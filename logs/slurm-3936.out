INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_FGDCC.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k_exp40',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 75,
                        'final_lr': 1e-05,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 8.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:PairedCrossAttentionClassifier(
  (act): GELU(approximate='none')
  (subclass_proj): Sequential(
    (0): Linear(in_features=1280, out_features=1280, bias=True)
    (1): GELU(approximate='none')
  )
  (parent_cross_attention): MultiHeadCrossAttention(
    (query): Linear(in_features=1280, out_features=1280, bias=True)
    (key): Linear(in_features=1280, out_features=1280, bias=True)
    (value): Linear(in_features=1280, out_features=1280, bias=True)
  )
  (subclass_cross_attention): MultiHeadCrossAttention(
    (query): Linear(in_features=1280, out_features=1280, bias=True)
    (key): Linear(in_features=1280, out_features=1280, bias=True)
    (value): Linear(in_features=1280, out_features=1280, bias=True)
  )
  (parent_feature_selection): Linear(in_features=2560, out_features=1280, bias=True)
  (subclass_feature_selection): Linear(in_features=2560, out_features=1280, bias=True)
  (parent_classifier): Linear(in_features=1280, out_features=1081, bias=True)
  (subclass_classifier): Linear(in_features=1280, out_features=4324, bias=True)
  (head_drop): Dropout(p=0.25, inplace=False)
)
INFO:root:Using AdamW
INFO:root:VisionTransformerAutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.2, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.2, inplace=False)
      )
    )
    (3): Linear(in_features=1024, out_features=768, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=768, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.2, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.2, inplace=False)
      )
    )
    (3): Linear(in_features=1024, out_features=1280, bias=True)
  )
)
INFO:root:VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
  )
  (blocks): ModuleList(
    (0-31): 32 x Block(
      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1280, out_features=3840, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1280, out_features=1280, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1280, out_features=5120, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
)
INFO:root:Autoencoder Training...
INFO:root: - - Epoch: 1 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 2.0071] [autoencoder lr: 9.00e-04][mem: 8.96e+03](2202.0 ms)
INFO:root:[1,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9225] [autoencoder lr: 9.00e-04][mem: 9.19e+03](430.4 ms)
INFO:root:[1,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8603] [autoencoder lr: 9.01e-04][mem: 9.19e+03](422.4 ms)
INFO:root:[1,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8166] [autoencoder lr: 9.01e-04][mem: 9.19e+03](419.4 ms)
INFO:root:[1,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7831] [autoencoder lr: 9.02e-04][mem: 9.19e+03](417.7 ms)
INFO:root:[1,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7560] [autoencoder lr: 9.02e-04][mem: 9.19e+03](417.5 ms)
INFO:root:[1,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7337] [autoencoder lr: 9.02e-04][mem: 9.19e+03](416.6 ms)
INFO:root:[1,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7146] [autoencoder lr: 9.03e-04][mem: 9.19e+03](416.2 ms)
INFO:root:[1,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6980] [autoencoder lr: 9.03e-04][mem: 9.19e+03](416.1 ms)
INFO:root:[1,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6837] [autoencoder lr: 9.04e-04][mem: 9.19e+03](416.2 ms)
INFO:root:[1,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6709] [autoencoder lr: 9.04e-04][mem: 9.19e+03](416.0 ms)
INFO:root:[1,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6596] [autoencoder lr: 9.04e-04][mem: 9.19e+03](415.7 ms)
INFO:root:[1,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6495] [autoencoder lr: 9.05e-04][mem: 9.19e+03](415.5 ms)
INFO:root:[1,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6405] [autoencoder lr: 9.05e-04][mem: 9.19e+03](415.3 ms)
INFO:root:[1,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6322] [autoencoder lr: 9.05e-04][mem: 9.19e+03](415.5 ms)
INFO:root:[1,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6245] [autoencoder lr: 9.06e-04][mem: 9.19e+03](415.3 ms)
INFO:root:[1,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6175] [autoencoder lr: 9.06e-04][mem: 9.19e+03](415.1 ms)
INFO:root:[1,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6111] [autoencoder lr: 9.07e-04][mem: 9.19e+03](415.0 ms)
INFO:root:[1,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.6051] [autoencoder lr: 9.07e-04][mem: 9.19e+03](414.9 ms)
INFO:root:[1,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5996] [autoencoder lr: 9.07e-04][mem: 9.19e+03](414.8 ms)
INFO:root:[1,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5944] [autoencoder lr: 9.08e-04][mem: 9.19e+03](415.0 ms)
INFO:root:[1,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5896] [autoencoder lr: 9.08e-04][mem: 9.19e+03](415.0 ms)
INFO:root:[1,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5850] [autoencoder lr: 9.09e-04][mem: 9.19e+03](414.9 ms)
INFO:root:[1,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5808] [autoencoder lr: 9.09e-04][mem: 9.19e+03](414.9 ms)
INFO:root:[1,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5768] [autoencoder lr: 9.09e-04][mem: 9.19e+03](414.9 ms)
INFO:root:[1,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.5730] [autoencoder lr: 9.10e-04][mem: 9.19e+03](415.0 ms)
INFO:root: - - Epoch: 2 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_FGDCC.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 546, in main
    cached_features_last_epoch, AE_scheduler, AE_optimizer = train_autoencoder(fgdcc=fgdcc,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 532, in train_autoencoder
    (ae_lr, reconstruction_loss, cache), elapsed_time = gpu_timer(train_step)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 507, in train_step
    reconstruction_loss, bottleneck_output, _, _ = fgdcc(imgs=x, device=device, autoencoder=True, cold_start=cold_start)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1593, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1411, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/models/FGDCC.py", line 44, in forward
    reconstructed_input, bottleneck_output = self.autoencoder(h, device)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/models/transformer_autoencoder.py", line 140, in forward
    reconstructed_input = self.decoder(bottleneck_output)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
 (Triggered internally at /opt/conda/conda-bld/pytorch_1716905969118/work/torch/csrc/autograd/python_anomaly_mode.cpp:111.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_FGDCC.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 546, in main
    cached_features_last_epoch, AE_scheduler, AE_optimizer = train_autoencoder(fgdcc=fgdcc,
                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 532, in train_autoencoder
    (ae_lr, reconstruction_loss, cache), elapsed_time = gpu_timer(train_step)
                                                        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
             ^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 520, in train_step
    scaler(reconstruction_loss, AE_optimizer, clip_grad=1.0,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/helper.py", line 156, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph, retain_graph=retain_graph)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Function 'AddmmBackward0' returned nan values in its 2th output.
