INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_FGDCC.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k_exp40',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 75,
                        'final_lr': 1e-05,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 2.5e-05,
                        'start_lr': 8.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:MaskedAutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1152, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1152, out_features=1024, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=1024, out_features=768, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=768, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1152, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=1152, out_features=1280, bias=True)
  )
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:PairedCrossAttentionClassifier(
  (act): GELU(approximate='none')
  (subclass_proj): Sequential(
    (0): Linear(in_features=1280, out_features=1280, bias=True)
    (1): GELU(approximate='none')
  )
  (parent_cross_attention): MultiHeadCrossAttention(
    (query): Linear(in_features=1280, out_features=1280, bias=True)
    (key): Linear(in_features=1280, out_features=1280, bias=True)
    (value): Linear(in_features=1280, out_features=1280, bias=True)
  )
  (subclass_cross_attention): MultiHeadCrossAttention(
    (query): Linear(in_features=1280, out_features=1280, bias=True)
    (key): Linear(in_features=1280, out_features=1280, bias=True)
    (value): Linear(in_features=1280, out_features=1280, bias=True)
  )
  (parent_feature_selection): Linear(in_features=2560, out_features=1280, bias=True)
  (subclass_feature_selection): Linear(in_features=2560, out_features=1280, bias=True)
  (parent_classifier): Linear(in_features=1280, out_features=1081, bias=True)
  (subclass_classifier): Linear(in_features=1280, out_features=4324, bias=True)
  (head_drop): Dropout(p=0.25, inplace=False)
)
INFO:root:Using AdamW
INFO:root:VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
  )
  (blocks): ModuleList(
    (0-31): 32 x Block(
      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1280, out_features=3840, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1280, out_features=1280, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=1280, out_features=5120, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=5120, out_features=1280, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
)
INFO:root:SpatialMaskedAutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1152, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1152, out_features=1024, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=1024, out_features=960, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=960, out_features=896, bias=True)
    (7): GELU(approximate='none')
    (8): Linear(in_features=896, out_features=832, bias=True)
    (9): GELU(approximate='none')
    (10): Linear(in_features=832, out_features=768, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=768, out_features=832, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=832, out_features=896, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=896, out_features=960, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=960, out_features=1024, bias=True)
    (7): GELU(approximate='none')
    (8): Linear(in_features=1024, out_features=1152, bias=True)
    (9): GELU(approximate='none')
    (10): Linear(in_features=1152, out_features=1280, bias=True)
  )
)
INFO:root:Autoencoder Training...
INFO:root: - - Epoch: 1 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9450] [autoencoder lr: 1.00e-04][mem: 8.39e+03](2297.6 ms)
INFO:root:[1,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9452] [autoencoder lr: 1.00e-04][mem: 8.90e+03](339.3 ms)
INFO:root:[1,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9454] [autoencoder lr: 1.01e-04][mem: 8.90e+03](330.4 ms)
INFO:root:[1,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.01e-04][mem: 8.90e+03](327.5 ms)
INFO:root:[1,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9450] [autoencoder lr: 1.02e-04][mem: 8.90e+03](326.1 ms)
INFO:root:[1,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9450] [autoencoder lr: 1.02e-04][mem: 8.90e+03](325.2 ms)
INFO:root:[1,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.02e-04][mem: 8.90e+03](324.6 ms)
INFO:root:[1,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.03e-04][mem: 8.90e+03](324.2 ms)
INFO:root:[1,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.03e-04][mem: 8.90e+03](323.8 ms)
INFO:root:[1,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.04e-04][mem: 8.90e+03](323.6 ms)
INFO:root:[1,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.04e-04][mem: 8.90e+03](323.4 ms)
INFO:root:[1,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9450] [autoencoder lr: 1.04e-04][mem: 8.90e+03](323.3 ms)
INFO:root:[1,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.05e-04][mem: 8.90e+03](323.2 ms)
INFO:root:[1,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.05e-04][mem: 8.90e+03](323.1 ms)
INFO:root:[1,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.05e-04][mem: 8.90e+03](323.0 ms)
INFO:root:[1,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.06e-04][mem: 8.90e+03](323.0 ms)
INFO:root:[1,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.06e-04][mem: 8.90e+03](323.0 ms)
INFO:root:[1,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.07e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.07e-04][mem: 8.90e+03](323.0 ms)
INFO:root:[1,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9452] [autoencoder lr: 1.07e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9452] [autoencoder lr: 1.08e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9452] [autoencoder lr: 1.08e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.09e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.09e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.09e-04][mem: 8.90e+03](322.9 ms)
INFO:root:[1,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9451] [autoencoder lr: 1.10e-04][mem: 8.90e+03](322.8 ms)
INFO:root: - - Epoch: 2 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[2,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9450] [autoencoder lr: 1.10e-04][mem: 8.90e+03](322.8 ms)
INFO:root:[2,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9375] [autoencoder lr: 1.10e-04][mem: 8.90e+03](322.7 ms)
INFO:root:[2,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9305] [autoencoder lr: 1.11e-04][mem: 8.90e+03](322.6 ms)
INFO:root:[2,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9240] [autoencoder lr: 1.11e-04][mem: 8.90e+03](322.5 ms)
INFO:root:[2,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9179] [autoencoder lr: 1.12e-04][mem: 8.90e+03](322.5 ms)
INFO:root:[2,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9122] [autoencoder lr: 1.12e-04][mem: 8.90e+03](322.5 ms)
INFO:root:[2,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9069] [autoencoder lr: 1.12e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.9019] [autoencoder lr: 1.13e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8972] [autoencoder lr: 1.13e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8928] [autoencoder lr: 1.14e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8886] [autoencoder lr: 1.14e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8847] [autoencoder lr: 1.14e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8810] [autoencoder lr: 1.15e-04][mem: 8.90e+03](322.3 ms)
INFO:root:[2,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8774] [autoencoder lr: 1.15e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8740] [autoencoder lr: 1.15e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8708] [autoencoder lr: 1.16e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8678] [autoencoder lr: 1.16e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8649] [autoencoder lr: 1.17e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8621] [autoencoder lr: 1.17e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8595] [autoencoder lr: 1.17e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8569] [autoencoder lr: 1.18e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8545] [autoencoder lr: 1.18e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8522] [autoencoder lr: 1.19e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8500] [autoencoder lr: 1.19e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8478] [autoencoder lr: 1.19e-04][mem: 8.90e+03](322.4 ms)
INFO:root:[2,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8458] [autoencoder lr: 1.20e-04][mem: 8.90e+03](322.4 ms)
INFO:root: - - Epoch: 3 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[3,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8446] [autoencoder lr: 1.20e-04][mem: 8.90e+03](322.3 ms)
INFO:root:[3,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8426] [autoencoder lr: 1.20e-04][mem: 8.90e+03](322.3 ms)
INFO:root:[3,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8408] [autoencoder lr: 1.21e-04][mem: 8.90e+03](322.3 ms)
INFO:root:[3,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8390] [autoencoder lr: 1.21e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8373] [autoencoder lr: 1.22e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8357] [autoencoder lr: 1.22e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8341] [autoencoder lr: 1.22e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8325] [autoencoder lr: 1.23e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8310] [autoencoder lr: 1.23e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8296] [autoencoder lr: 1.24e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8282] [autoencoder lr: 1.24e-04][mem: 8.90e+03](322.2 ms)
INFO:root:[3,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8268] [autoencoder lr: 1.24e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8255] [autoencoder lr: 1.25e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8242] [autoencoder lr: 1.25e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8230] [autoencoder lr: 1.25e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8218] [autoencoder lr: 1.26e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8206] [autoencoder lr: 1.26e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8195] [autoencoder lr: 1.27e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8185] [autoencoder lr: 1.27e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8174] [autoencoder lr: 1.27e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8164] [autoencoder lr: 1.28e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8154] [autoencoder lr: 1.28e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8144] [autoencoder lr: 1.29e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8135] [autoencoder lr: 1.29e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8126] [autoencoder lr: 1.29e-04][mem: 8.90e+03](322.1 ms)
INFO:root:[3,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8117] [autoencoder lr: 1.30e-04][mem: 8.90e+03](322.0 ms)
INFO:root: - - Epoch: 4 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[4,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8111] [autoencoder lr: 1.30e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8103] [autoencoder lr: 1.30e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8094] [autoencoder lr: 1.31e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8086] [autoencoder lr: 1.31e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8078] [autoencoder lr: 1.32e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8071] [autoencoder lr: 1.32e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[4,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8063] [autoencoder lr: 1.32e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[4,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8056] [autoencoder lr: 1.33e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[4,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8049] [autoencoder lr: 1.33e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[4,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8041] [autoencoder lr: 1.34e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[4,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8034] [autoencoder lr: 1.34e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8028] [autoencoder lr: 1.34e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8021] [autoencoder lr: 1.35e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8015] [autoencoder lr: 1.35e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8008] [autoencoder lr: 1.35e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.8002] [autoencoder lr: 1.36e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7996] [autoencoder lr: 1.36e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7990] [autoencoder lr: 1.37e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7984] [autoencoder lr: 1.37e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7979] [autoencoder lr: 1.37e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7973] [autoencoder lr: 1.38e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7968] [autoencoder lr: 1.38e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7962] [autoencoder lr: 1.39e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7957] [autoencoder lr: 1.39e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7952] [autoencoder lr: 1.39e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[4,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7947] [autoencoder lr: 1.40e-04][mem: 8.90e+03](322.0 ms)
INFO:root: - - Epoch: 5 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[5,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7944] [autoencoder lr: 1.40e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7939] [autoencoder lr: 1.40e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7934] [autoencoder lr: 1.41e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7929] [autoencoder lr: 1.41e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7925] [autoencoder lr: 1.42e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7920] [autoencoder lr: 1.42e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7916] [autoencoder lr: 1.42e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7912] [autoencoder lr: 1.43e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7907] [autoencoder lr: 1.43e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7903] [autoencoder lr: 1.44e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7899] [autoencoder lr: 1.44e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7895] [autoencoder lr: 1.44e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7891] [autoencoder lr: 1.45e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7887] [autoencoder lr: 1.45e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7883] [autoencoder lr: 1.45e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7879] [autoencoder lr: 1.46e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7876] [autoencoder lr: 1.46e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7872] [autoencoder lr: 1.47e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7868] [autoencoder lr: 1.47e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7865] [autoencoder lr: 1.47e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7861] [autoencoder lr: 1.48e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7858] [autoencoder lr: 1.48e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7855] [autoencoder lr: 1.49e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7851] [autoencoder lr: 1.49e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[5,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7848] [autoencoder lr: 1.49e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[5,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7845] [autoencoder lr: 1.50e-04][mem: 8.90e+03](321.9 ms)
INFO:root: - - Epoch: 6 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[6,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7843] [autoencoder lr: 1.50e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7840] [autoencoder lr: 1.50e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7837] [autoencoder lr: 1.51e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7834] [autoencoder lr: 1.51e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7831] [autoencoder lr: 1.52e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7828] [autoencoder lr: 1.52e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7825] [autoencoder lr: 1.52e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7822] [autoencoder lr: 1.53e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7819] [autoencoder lr: 1.53e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7817] [autoencoder lr: 1.54e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7814] [autoencoder lr: 1.54e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7811] [autoencoder lr: 1.54e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7809] [autoencoder lr: 1.55e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7806] [autoencoder lr: 1.55e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7803] [autoencoder lr: 1.55e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7801] [autoencoder lr: 1.56e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7798] [autoencoder lr: 1.56e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7796] [autoencoder lr: 1.57e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7793] [autoencoder lr: 1.57e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7791] [autoencoder lr: 1.57e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7789] [autoencoder lr: 1.58e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7786] [autoencoder lr: 1.58e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7784] [autoencoder lr: 1.59e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7782] [autoencoder lr: 1.59e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7780] [autoencoder lr: 1.59e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[6,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7777] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root: - - Epoch: 7 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[7,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7776] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7774] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7772] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7770] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7768] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7765] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7763] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7761] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7759] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[7,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7758] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7756] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7754] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7752] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7750] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7748] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7746] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7745] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7743] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7741] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7739] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7738] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7736] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7734] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7733] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7731] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[7,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7729] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.9 ms)
INFO:root: - - Epoch: 8 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[8,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7728] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[8,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7727] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[8,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7725] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[8,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7724] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7722] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7721] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7719] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7718] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7716] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7715] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7713] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7712] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7711] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7709] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7708] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7706] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7705] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7704] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7702] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7701] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7700] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7699] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7697] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7696] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7695] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[8,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7694] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 9 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[9,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7693] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7692] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7690] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7689] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7688] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7687] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7686] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7685] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7683] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7682] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7681] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7680] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7679] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7678] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7677] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7676] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7675] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7674] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7673] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7671] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7670] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7669] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7668] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7667] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7666] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[9,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7665] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 10 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[10,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7665] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[10,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7664] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[10,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7663] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[10,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7662] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[10,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7661] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[10,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7660] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7659] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7658] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7657] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7656] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7655] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7654] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7654] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7653] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7652] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7651] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7650] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7649] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7648] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7648] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7647] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7646] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7645] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7644] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7644] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[10,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7643] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 11 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[11,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7642] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7642] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7641] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7640] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7639] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7638] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7638] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7637] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7636] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7635] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7635] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7634] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7633] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7633] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7632] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7631] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7631] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7630] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7629] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7629] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7628] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7627] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7627] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7626] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7625] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[11,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7625] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 12 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[12,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7624] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7624] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7623] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7622] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7622] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7621] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7620] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7620] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7619] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7619] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7618] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7617] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7617] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7616] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7616] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7615] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7614] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7614] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7613] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7613] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7612] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[12,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7611] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[12,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7611] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[12,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7610] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[12,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7610] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[12,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7609] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 13 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[13,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7609] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7608] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7608] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7607] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7607] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7606] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7606] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7605] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7605] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7604] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7604] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7603] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7603] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7602] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7602] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[13,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7601] [autoencoder lr: 2.00e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7601] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7600] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7600] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7599] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7599] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7598] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7598] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7597] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7597] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[13,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7596] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 14 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[14,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7596] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7595] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7595] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7595] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7594] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7594] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7593] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7593] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7592] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7592] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7591] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7591] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7591] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7590] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7590] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[14,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7589] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7589] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7588] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7588] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7588] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7587] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7587] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7586] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7586] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7586] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[14,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7585] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 15 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[15,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7585] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7585] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7584] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7584] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7583] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7583] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7583] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7582] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7582] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7581] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7581] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7581] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[15,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7580] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7580] [autoencoder lr: 1.99e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7580] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7579] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7579] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7578] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7578] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7578] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7577] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7577] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7577] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7576] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7576] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[15,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7576] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 16 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[16,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7575] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7575] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7575] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7574] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7574] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7574] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7573] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7573] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7573] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7572] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7572] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7572] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7571] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7571] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7571] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7571] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7570] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7570] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7570] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7569] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7569] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7569] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7568] [autoencoder lr: 1.98e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7568] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7568] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[16,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7567] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 17 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[17,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7567] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7567] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7567] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7566] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7566] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7566] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7565] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7565] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7565] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7564] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7564] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7564] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7564] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7563] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7563] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7563] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7562] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7562] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7562] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7562] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7561] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7561] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7561] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7561] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7560] [autoencoder lr: 1.97e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[17,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7560] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root: - - Epoch: 18 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[18,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7560] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7560] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7559] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7559] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7559] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7558] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7558] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7558] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7558] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7557] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7557] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7557] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7556] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7556] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7556] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7556] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7555] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7555] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[18,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7555] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7555] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7555] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7554] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7554] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7554] [autoencoder lr: 1.96e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7553] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[18,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7553] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 19 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[19,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7553] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7553] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7553] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7552] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7552] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7552] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7552] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7551] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7551] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7551] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7551] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7551] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7550] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7550] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7550] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7550] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7549] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7549] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7549] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7549] [autoencoder lr: 1.95e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7548] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7548] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7548] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7548] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7548] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[19,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7547] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 20 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[20,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7547] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7547] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7547] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7547] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7546] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7546] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7546] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7546] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7545] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7545] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7545] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7545] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7545] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7544] [autoencoder lr: 1.94e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7544] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7544] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7544] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7544] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7543] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7543] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7543] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7543] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7543] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7542] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7542] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[20,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7542] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 21 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[21,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7542] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7542] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7541] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7541] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7541] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7541] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7541] [autoencoder lr: 1.93e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7541] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7540] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7540] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7540] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7540] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7540] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7539] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7539] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7539] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7539] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7539] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7538] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7538] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7538] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7538] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7538] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7537] [autoencoder lr: 1.92e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7537] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[21,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7537] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 22 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[22,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7537] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7537] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7537] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7536] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7536] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7536] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7536] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7536] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7536] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7535] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7535] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7535] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7535] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7535] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7535] [autoencoder lr: 1.91e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7534] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7534] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7534] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7534] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7534] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7534] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7533] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7533] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7533] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7533] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[22,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7533] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 23 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[23,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7533] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.90e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7532] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7531] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7531] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7531] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7531] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7531] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7531] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.89e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7530] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7529] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7529] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7529] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7529] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[23,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7529] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 24 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[24,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7529] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7528] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.88e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7527] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7526] [autoencoder lr: 1.87e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[24,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 25 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[25,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7525] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.86e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7524] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7523] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.85e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[25,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 26 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[26,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7522] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7521] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.84e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7520] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.83e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[26,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7519] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 27 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[27,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7518] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.82e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7517] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.81e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[27,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 28 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[28,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7516] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.80e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7515] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.79e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7514] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[28,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 29 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[29,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7513] [autoencoder lr: 1.78e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7512] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.77e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7511] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[29,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.76e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 30 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[30,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7510] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.75e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7509] [autoencoder lr: 1.74e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[30,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 31 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[31,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.73e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7508] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.72e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7507] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[31,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.71e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 32 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[32,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7506] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.70e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7505] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.69e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[32,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 33 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[33,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.68e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7504] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.67e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7503] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.66e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[33,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 34 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[34,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.65e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7502] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.64e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7501] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[34,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.63e-04][mem: 8.90e+03](321.7 ms)
INFO:root: - - Epoch: 35 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[35,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[35,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[35,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[35,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[35,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[35,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.7 ms)
INFO:root:[35,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.62e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7500] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.8 ms)
INFO:root:[35,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.61e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](321.9 ms)
INFO:root:[35,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[35,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](322.0 ms)
INFO:root:[35,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: 1.7499] [autoencoder lr: 1.60e-04][mem: 8.90e+03](322.0 ms)
INFO:root:Initializing centroids...
INFO:root:Update Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
[rank0]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
parent logits: tensor([[ 5.7369e-07, -2.2352e-07, -7.0781e-07,  ..., -6.3330e-07,
         -1.0012e-07, -2.7474e-08],
        [ 8.2701e-07, -8.9407e-07, -5.5134e-07,  ..., -1.7602e-07,
          7.4040e-08,  2.0023e-08],
        [ 6.4727e-08, -8.6613e-08,  1.8906e-07,  ...,  1.9465e-07,
         -4.7963e-08,  2.4401e-07],
        ...,
        [-1.4063e-07, -7.8231e-07, -1.0654e-06,  ..., -5.6624e-07,
         -2.6450e-07,  1.3877e-07],
        [-3.4645e-07, -3.3062e-08,  3.4273e-07,  ...,  9.1270e-08,
          3.3714e-07,  1.3784e-07],
        [-4.9919e-07, -3.7253e-07,  2.4401e-07,  ...,  1.1083e-07,
          4.8894e-09, -8.9873e-08]], device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[-9.5461e-09,  3.0175e-07,  2.7567e-07,  ..., -4.3213e-07,
          6.4820e-07,  8.8476e-08],
        [-4.7125e-07,  3.7253e-07, -7.1898e-07,  ...,  2.1886e-07,
          1.0282e-06,  3.1851e-07],
        [ 7.1153e-07, -2.3562e-07,  1.4785e-08,  ...,  7.4878e-07,
         -2.6077e-07,  1.0133e-06],
        ...,
        [-1.1874e-08, -2.9989e-07, -2.0675e-07,  ...,  1.3933e-06,
         -1.7416e-07, -9.5367e-07],
        [-7.0035e-07,  2.9802e-07,  7.7859e-07,  ...,  1.1735e-07,
          7.8231e-07,  2.6077e-07],
        [-3.8184e-07, -2.6263e-07,  5.4389e-07,  ..., -1.0133e-06,
          7.0315e-08,  7.8604e-07]], device='cuda:0', dtype=torch.bfloat16,
       grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     0/ 2562] - train_losses - Parent Class: 6.9856 - Children class: 8.3719 -Autoencoder Loss (total): 305224679424.0000 - Reconstruction/K-Means Loss: [1.7499 / 305224679424.0000] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.39e+04] (1942.1 ms)
INFO:root:[1,     0] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     1/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / 9816406196224.0000] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1923.1 ms)
INFO:root:[1,     1] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     2/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1677.8 ms)
INFO:root:[1,     2] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     3/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1553.1 ms)
INFO:root:[1,     3] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     4/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1471.3 ms)
INFO:root:[1,     4] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     5/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1417.2 ms)
INFO:root:[1,     5] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     6/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1378.9 ms)
INFO:root:[1,     6] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     7/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1348.7 ms)
INFO:root:[1,     7] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     8/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1324.8 ms)
INFO:root:[1,     8] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,     9/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.50e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1305.2 ms)
INFO:root:[1,     9] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    10/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1289.7 ms)
INFO:root:[1,    10] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    11/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1276.6 ms)
INFO:root:[1,    11] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    12/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1265.6 ms)
INFO:root:[1,    12] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    13/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1256.2 ms)
INFO:root:[1,    13] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    14/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1248.3 ms)
INFO:root:[1,    14] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    15/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1240.9 ms)
INFO:root:[1,    15] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    16/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1234.5 ms)
INFO:root:[1,    16] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    17/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1228.7 ms)
INFO:root:[1,    17] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    18/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1222.4 ms)
INFO:root:[1,    18] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    19/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1217.0 ms)
INFO:root:[1,    19] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    20/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1212.9 ms)
INFO:root:[1,    20] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    21/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1209.4 ms)
INFO:root:[1,    21] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    22/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1206.0 ms)
INFO:root:[1,    22] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    23/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1203.0 ms)
INFO:root:[1,    23] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    24/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1200.1 ms)
INFO:root:[1,    24] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    25/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1197.2 ms)
INFO:root:[1,    25] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    26/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1194.7 ms)
INFO:root:[1,    26] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    27/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1192.3 ms)
INFO:root:[1,    27] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    28/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1190.2 ms)
INFO:root:[1,    28] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    29/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1188.1 ms)
INFO:root:[1,    29] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    30/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1186.2 ms)
INFO:root:[1,    30] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    31/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.49e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1184.4 ms)
INFO:root:[1,    31] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    32/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1182.7 ms)
INFO:root:[1,    32] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    33/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1181.1 ms)
INFO:root:[1,    33] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    34/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1179.5 ms)
INFO:root:[1,    34] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    35/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1178.1 ms)
INFO:root:[1,    35] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    36/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1176.9 ms)
INFO:root:[1,    36] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    37/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1175.6 ms)
INFO:root:[1,    37] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    38/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1174.4 ms)
INFO:root:[1,    38] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    39/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1173.3 ms)
INFO:root:[1,    39] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    40/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1172.2 ms)
INFO:root:[1,    40] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    41/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1171.2 ms)
INFO:root:[1,    41] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    42/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1170.4 ms)
INFO:root:[1,    42] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    43/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1169.1 ms)
INFO:root:[1,    43] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    44/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1168.3 ms)
INFO:root:[1,    44] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    45/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1167.4 ms)
INFO:root:[1,    45] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    46/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1166.6 ms)
INFO:root:[1,    46] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    47/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1165.8 ms)
INFO:root:[1,    47] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    48/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1165.1 ms)
INFO:root:[1,    48] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    49/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1164.4 ms)
INFO:root:[1,    49] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    50/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1163.7 ms)
INFO:root:[1,    50] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    51/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1163.1 ms)
INFO:root:[1,    51] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    52/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.48e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1162.6 ms)
INFO:root:[1,    52] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    53/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1162.1 ms)
INFO:root:[1,    53] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    54/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1161.6 ms)
INFO:root:[1,    54] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    55/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1161.0 ms)
INFO:root:[1,    55] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    56/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1160.6 ms)
INFO:root:[1,    56] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    57/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1160.0 ms)
INFO:root:[1,    57] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    58/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1159.5 ms)
INFO:root:[1,    58] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    59/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1159.0 ms)
INFO:root:[1,    59] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    60/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1158.6 ms)
INFO:root:[1,    60] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    61/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1158.1 ms)
INFO:root:[1,    61] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    62/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1157.7 ms)
INFO:root:[1,    62] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    63/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1157.2 ms)
INFO:root:[1,    63] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    64/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1156.8 ms)
INFO:root:[1,    64] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    65/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1156.4 ms)
INFO:root:[1,    65] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    66/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1156.0 ms)
INFO:root:[1,    66] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    67/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1155.6 ms)
INFO:root:[1,    67] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    68/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1155.2 ms)
INFO:root:[1,    68] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    69/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1154.8 ms)
INFO:root:[1,    69] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    70/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1154.5 ms)
INFO:root:[1,    70] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    71/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1154.3 ms)
INFO:root:[1,    71] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    72/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1154.0 ms)
INFO:root:[1,    72] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    73/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.47e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1153.7 ms)
INFO:root:[1,    73] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    74/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1153.4 ms)
INFO:root:[1,    74] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    75/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1153.1 ms)
INFO:root:[1,    75] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    76/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1152.9 ms)
INFO:root:[1,    76] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    77/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1152.6 ms)
INFO:root:[1,    77] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    78/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1152.4 ms)
INFO:root:[1,    78] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    79/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1152.2 ms)
INFO:root:[1,    79] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    80/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1152.0 ms)
INFO:root:[1,    80] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    81/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1151.8 ms)
INFO:root:[1,    81] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    82/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1151.6 ms)
INFO:root:[1,    82] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    83/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1151.4 ms)
INFO:root:[1,    83] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    84/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1151.2 ms)
INFO:root:[1,    84] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    85/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1151.0 ms)
INFO:root:[1,    85] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    86/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1150.8 ms)
INFO:root:[1,    86] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    87/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1150.6 ms)
INFO:root:[1,    87] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    88/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1150.4 ms)
INFO:root:[1,    88] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    89/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1150.2 ms)
INFO:root:[1,    89] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    90/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1150.0 ms)
INFO:root:[1,    90] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    91/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1149.8 ms)
INFO:root:[1,    91] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    92/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1149.6 ms)
INFO:root:[1,    92] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    93/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1149.5 ms)
INFO:root:[1,    93] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    94/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1149.3 ms)
INFO:root:[1,    94] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    95/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.46e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1149.1 ms)
INFO:root:[1,    95] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    96/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.9 ms)
INFO:root:[1,    96] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    97/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.9 ms)
INFO:root:[1,    97] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    98/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.8 ms)
INFO:root:[1,    98] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,    99/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1149.0 ms)
INFO:root:[1,    99] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   100/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.8 ms)
INFO:root:[1,   100] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   101/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.8 ms)
INFO:root:[1,   101] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   102/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.7 ms)
INFO:root:[1,   102] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   103/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.5 ms)
INFO:root:[1,   103] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   104/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.4 ms)
INFO:root:[1,   104] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   105/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.3 ms)
INFO:root:[1,   105] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   106/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.2 ms)
INFO:root:[1,   106] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   107/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.1 ms)
INFO:root:[1,   107] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   108/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1148.0 ms)
INFO:root:[1,   108] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   109/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.8 ms)
INFO:root:[1,   109] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   110/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.8 ms)
INFO:root:[1,   110] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   111/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.7 ms)
INFO:root:[1,   111] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   112/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.6 ms)
INFO:root:[1,   112] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   113/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.5 ms)
INFO:root:[1,   113] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   114/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.4 ms)
INFO:root:[1,   114] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   115/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.3 ms)
INFO:root:[1,   115] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   116/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.45e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.2 ms)
INFO:root:[1,   116] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   117/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.1 ms)
INFO:root:[1,   117] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   118/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.1 ms)
INFO:root:[1,   118] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   119/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1147.0 ms)
INFO:root:[1,   119] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   120/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.9 ms)
INFO:root:[1,   120] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   121/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   121] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   122/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.7 ms)
INFO:root:[1,   122] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   123/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   123] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   124/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   124] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   125/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.5 ms)
INFO:root:[1,   125] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   126/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.5 ms)
INFO:root:[1,   126] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   127/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.4 ms)
INFO:root:[1,   127] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   128/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.3 ms)
INFO:root:[1,   128] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   129/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   129] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   130/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.1 ms)
INFO:root:[1,   130] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   131/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.1 ms)
INFO:root:[1,   131] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   132/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.1 ms)
INFO:root:[1,   132] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   133/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.0 ms)
INFO:root:[1,   133] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   134/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1146.0 ms)
INFO:root:[1,   134] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   135/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   135] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   136/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   136] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   137/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.44e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   137] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   138/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   138] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   139/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.8 ms)
INFO:root:[1,   139] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   140/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.8 ms)
INFO:root:[1,   140] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   141/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   141] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   142/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   142] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   143/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   143] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   144/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   144] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   145/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   145] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   146/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.60e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   146] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   147/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   147] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   148/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   148] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   149/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   149] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   150/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   150] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   151/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   151] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   152/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   152] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   153/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   153] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   154/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   154] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   155/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   155] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   156/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   156] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   157/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   157] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   158/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   158] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   159/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.43e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   159] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   160/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   160] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   161/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   161] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   162/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   162] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   163/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.0 ms)
INFO:root:[1,   163] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   164/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.0 ms)
INFO:root:[1,   164] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   165/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   165] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   166/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   166] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   167/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   167] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   168/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   168] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   169/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   169] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   170/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   170] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   171/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   171] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   172/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   172] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   173/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   173] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   174/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   174] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   175/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   175] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   176/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   176] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   177/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   177] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   178/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   178] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   179/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   179] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   180/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.42e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   180] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   181/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   181] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   182/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   182] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   183/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   183] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   184/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   184] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   185/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   185] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   186/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   186] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   187/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   187] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   188/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   188] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   189/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   189] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   190/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   190] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   191/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   191] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   192/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   192] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   193/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   193] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   194/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   194] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   195/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   195] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   196/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   196] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   197/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   197] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   198/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   198] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   199/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   199] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   200/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   200] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   201/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.41e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   201] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   202/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   202] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   203/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   203] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   204/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   204] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   205/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   205] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   206/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   206] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   207/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   207] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   208/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   208] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   209/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   209] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   210/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   210] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   211/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.6 ms)
INFO:root:[1,   211] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   212/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   212] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   213/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   213] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   214/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   214] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   215/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   215] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   216/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   216] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   217/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.7 ms)
INFO:root:[1,   217] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   218/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   218] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   219/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   219] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   220/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   220] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   221/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   221] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   222/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.8 ms)
INFO:root:[1,   222] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   223/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.40e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   223] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   224/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   224] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   225/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   225] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   226/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1144.9 ms)
INFO:root:[1,   226] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   227/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.0 ms)
INFO:root:[1,   227] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   228/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.0 ms)
INFO:root:[1,   228] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   229/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   229] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   230/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   230] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   231/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   231] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   232/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   232] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   233/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   233] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   234/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   234] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   235/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.1 ms)
INFO:root:[1,   235] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   236/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   236] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   237/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   237] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   238/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   238] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   239/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   239] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   240/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   240] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   241/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.2 ms)
INFO:root:[1,   241] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   242/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   242] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   243/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   243] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   244/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.39e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   244] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   245/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   245] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   246/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   246] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   247/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   247] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   248/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   248] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   249/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.3 ms)
INFO:root:[1,   249] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   250/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   250] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   251/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   251] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   252/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   252] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   253/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   253] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   254/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.4 ms)
INFO:root:[1,   254] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   255/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   255] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   256/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   256] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   257/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   257] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   258/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   258] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   259/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   259] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   260/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   260] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   261/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   261] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   262/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.5 ms)
INFO:root:[1,   262] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   263/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   263] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   264/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   264] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   265/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.38e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   265] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   266/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   266] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   267/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.6 ms)
INFO:root:[1,   267] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   268/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   268] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   269/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   269] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   270/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   270] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   271/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.7 ms)
INFO:root:[1,   271] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   272/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.8 ms)
INFO:root:[1,   272] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   273/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.8 ms)
INFO:root:[1,   273] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   274/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   274] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   275/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   275] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   276/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   276] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   277/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1145.9 ms)
INFO:root:[1,   277] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   278/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.0 ms)
INFO:root:[1,   278] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   279/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.0 ms)
INFO:root:[1,   279] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   280/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.0 ms)
INFO:root:[1,   280] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   281/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.0 ms)
INFO:root:[1,   281] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   282/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.1 ms)
INFO:root:[1,   282] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   283/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.1 ms)
INFO:root:[1,   283] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   284/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   284] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   285/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   285] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   286/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   286] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   287/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.37e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   287] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   288/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   288] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   289/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   289] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   290/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.2 ms)
INFO:root:[1,   290] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   291/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.3 ms)
INFO:root:[1,   291] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   292/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.3 ms)
INFO:root:[1,   292] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   293/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.3 ms)
INFO:root:[1,   293] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   294/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.3 ms)
INFO:root:[1,   294] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   295/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.4 ms)
INFO:root:[1,   295] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   296/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.4 ms)
INFO:root:[1,   296] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   297/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.4 ms)
INFO:root:[1,   297] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   298/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.4 ms)
INFO:root:[1,   298] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   299/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.5 ms)
INFO:root:[1,   299] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   300/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.5 ms)
INFO:root:[1,   300] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   301/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   301] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   302/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   302] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   303/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   303] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   304/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   304] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   305/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   305] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   306/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   306] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   307/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.6 ms)
INFO:root:[1,   307] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   308/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.36e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.7 ms)
INFO:root:[1,   308] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   309/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.7 ms)
INFO:root:[1,   309] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   310/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   310] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   311/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   311] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   312/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   312] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   313/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   313] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   314/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   314] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   315/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.8 ms)
INFO:root:[1,   315] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   316/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1146.9 ms)
INFO:root:[1,   316] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   317/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.0 ms)
INFO:root:[1,   317] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   318/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.1 ms)
INFO:root:[1,   318] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   319/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.1 ms)
INFO:root:[1,   319] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   320/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.2 ms)
INFO:root:[1,   320] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   321/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.2 ms)
INFO:root:[1,   321] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   322/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.3 ms)
INFO:root:[1,   322] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   323/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.3 ms)
INFO:root:[1,   323] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   324/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.3 ms)
INFO:root:[1,   324] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   325/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.3 ms)
INFO:root:[1,   325] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   326/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.4 ms)
INFO:root:[1,   326] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   327/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.4 ms)
INFO:root:[1,   327] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   328/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.4 ms)
INFO:root:[1,   328] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   329/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.35e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.5 ms)
INFO:root:[1,   329] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   330/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.5 ms)
INFO:root:[1,   330] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   331/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.6 ms)
INFO:root:[1,   331] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   332/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.6 ms)
INFO:root:[1,   332] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   333/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.7 ms)
INFO:root:[1,   333] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   334/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.7 ms)
INFO:root:[1,   334] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   335/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.7 ms)
INFO:root:[1,   335] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   336/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.8 ms)
INFO:root:[1,   336] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   337/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.8 ms)
INFO:root:[1,   337] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   338/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.9 ms)
INFO:root:[1,   338] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   339/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.9 ms)
INFO:root:[1,   339] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   340/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1147.9 ms)
INFO:root:[1,   340] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   341/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.0 ms)
INFO:root:[1,   341] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   342/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.0 ms)
INFO:root:[1,   342] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   343/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.1 ms)
INFO:root:[1,   343] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   344/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.1 ms)
INFO:root:[1,   344] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   345/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.1 ms)
INFO:root:[1,   345] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   346/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.1 ms)
INFO:root:[1,   346] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   347/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.2 ms)
INFO:root:[1,   347] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   348/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.2 ms)
INFO:root:[1,   348] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   349/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.3 ms)
INFO:root:[1,   349] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   350/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.3 ms)
INFO:root:[1,   350] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   351/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.34e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.4 ms)
INFO:root:[1,   351] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   352/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.4 ms)
INFO:root:[1,   352] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   353/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.4 ms)
INFO:root:[1,   353] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   354/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.5 ms)
INFO:root:[1,   354] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   355/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.5 ms)
INFO:root:[1,   355] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   356/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.5 ms)
INFO:root:[1,   356] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   357/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.6 ms)
INFO:root:[1,   357] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   358/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.6 ms)
INFO:root:[1,   358] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   359/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.7 ms)
INFO:root:[1,   359] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   360/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.7 ms)
INFO:root:[1,   360] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   361/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.8 ms)
INFO:root:[1,   361] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   362/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.9 ms)
INFO:root:[1,   362] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   363/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1148.9 ms)
INFO:root:[1,   363] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   364/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.0 ms)
INFO:root:[1,   364] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   365/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.1 ms)
INFO:root:[1,   365] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   366/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.1 ms)
INFO:root:[1,   366] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   367/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.1 ms)
INFO:root:[1,   367] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   368/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.2 ms)
INFO:root:[1,   368] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   369/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.2 ms)
INFO:root:[1,   369] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   370/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.3 ms)
INFO:root:[1,   370] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   371/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.3 ms)
INFO:root:[1,   371] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   372/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.33e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.4 ms)
INFO:root:[1,   372] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   373/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.4 ms)
INFO:root:[1,   373] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   374/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.5 ms)
INFO:root:[1,   374] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   375/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.5 ms)
INFO:root:[1,   375] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   376/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.6 ms)
INFO:root:[1,   376] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   377/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.6 ms)
INFO:root:[1,   377] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   378/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.7 ms)
INFO:root:[1,   378] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   379/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.7 ms)
INFO:root:[1,   379] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   380/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.8 ms)
INFO:root:[1,   380] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   381/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.8 ms)
INFO:root:[1,   381] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   382/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.8 ms)
INFO:root:[1,   382] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   383/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.8 ms)
INFO:root:[1,   383] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   384/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.9 ms)
INFO:root:[1,   384] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   385/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.9 ms)
INFO:root:[1,   385] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   386/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.9 ms)
INFO:root:[1,   386] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   387/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1149.9 ms)
INFO:root:[1,   387] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   388/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.0 ms)
INFO:root:[1,   388] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   389/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.1 ms)
INFO:root:[1,   389] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   390/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.1 ms)
INFO:root:[1,   390] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   391/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.2 ms)
INFO:root:[1,   391] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   392/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.2 ms)
INFO:root:[1,   392] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   393/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.32e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.2 ms)
INFO:root:[1,   393] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   394/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.3 ms)
INFO:root:[1,   394] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   395/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.3 ms)
INFO:root:[1,   395] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   396/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.4 ms)
INFO:root:[1,   396] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   397/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.4 ms)
INFO:root:[1,   397] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   398/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.5 ms)
INFO:root:[1,   398] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   399/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.5 ms)
INFO:root:[1,   399] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   400/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.5 ms)
INFO:root:[1,   400] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   401/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.5 ms)
INFO:root:[1,   401] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   402/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.5 ms)
INFO:root:[1,   402] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   403/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.6 ms)
INFO:root:[1,   403] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   404/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.7 ms)
INFO:root:[1,   404] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   405/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.8 ms)
INFO:root:[1,   405] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   406/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.8 ms)
INFO:root:[1,   406] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   407/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.9 ms)
INFO:root:[1,   407] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   408/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1150.9 ms)
INFO:root:[1,   408] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   409/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.0 ms)
INFO:root:[1,   409] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   410/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.0 ms)
INFO:root:[1,   410] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   411/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.1 ms)
INFO:root:[1,   411] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   412/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.2 ms)
INFO:root:[1,   412] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   413/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.2 ms)
INFO:root:[1,   413] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   414/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.3 ms)
INFO:root:[1,   414] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   415/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.31e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.3 ms)
INFO:root:[1,   415] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   416/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.3 ms)
INFO:root:[1,   416] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   417/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.4 ms)
INFO:root:[1,   417] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   418/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.4 ms)
INFO:root:[1,   418] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   419/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.4 ms)
INFO:root:[1,   419] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   420/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.5 ms)
INFO:root:[1,   420] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   421/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.5 ms)
INFO:root:[1,   421] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   422/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.6 ms)
INFO:root:[1,   422] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   423/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.6 ms)
INFO:root:[1,   423] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   424/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.7 ms)
INFO:root:[1,   424] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   425/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.7 ms)
INFO:root:[1,   425] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   426/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.7 ms)
INFO:root:[1,   426] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   427/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.8 ms)
INFO:root:[1,   427] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   428/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.8 ms)
INFO:root:[1,   428] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   429/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.9 ms)
INFO:root:[1,   429] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   430/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1151.9 ms)
INFO:root:[1,   430] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   431/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.0 ms)
INFO:root:[1,   431] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   432/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.0 ms)
INFO:root:[1,   432] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   433/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.0 ms)
INFO:root:[1,   433] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   434/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.1 ms)
INFO:root:[1,   434] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   435/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.1 ms)
INFO:root:[1,   435] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   436/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.30e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.2 ms)
INFO:root:[1,   436] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   437/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.2 ms)
INFO:root:[1,   437] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   438/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.3 ms)
INFO:root:[1,   438] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   439/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.4 ms)
INFO:root:[1,   439] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   440/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.4 ms)
INFO:root:[1,   440] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   441/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.5 ms)
INFO:root:[1,   441] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   442/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.5 ms)
INFO:root:[1,   442] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   443/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.6 ms)
INFO:root:[1,   443] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   444/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.6 ms)
INFO:root:[1,   444] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   445/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.7 ms)
INFO:root:[1,   445] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   446/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.7 ms)
INFO:root:[1,   446] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   447/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.8 ms)
INFO:root:[1,   447] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   448/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1152.9 ms)
INFO:root:[1,   448] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   449/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.0 ms)
INFO:root:[1,   449] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   450/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.0 ms)
INFO:root:[1,   450] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   451/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.1 ms)
INFO:root:[1,   451] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   452/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.2 ms)
INFO:root:[1,   452] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   453/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.2 ms)
INFO:root:[1,   453] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   454/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.3 ms)
INFO:root:[1,   454] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   455/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.3 ms)
INFO:root:[1,   455] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   456/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.4 ms)
INFO:root:[1,   456] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   457/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.4 ms)
INFO:root:[1,   457] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   458/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.29e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.5 ms)
INFO:root:[1,   458] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   459/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.5 ms)
INFO:root:[1,   459] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   460/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.6 ms)
INFO:root:[1,   460] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   461/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.7 ms)
INFO:root:[1,   461] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   462/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.7 ms)
INFO:root:[1,   462] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   463/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.8 ms)
INFO:root:[1,   463] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   464/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.8 ms)
INFO:root:[1,   464] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   465/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.9 ms)
INFO:root:[1,   465] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   466/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1153.9 ms)
INFO:root:[1,   466] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   467/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.0 ms)
INFO:root:[1,   467] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   468/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.0 ms)
INFO:root:[1,   468] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   469/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.0 ms)
INFO:root:[1,   469] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   470/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.0 ms)
INFO:root:[1,   470] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   471/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.1 ms)
INFO:root:[1,   471] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   472/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.1 ms)
INFO:root:[1,   472] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   473/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.2 ms)
INFO:root:[1,   473] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   474/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.3 ms)
INFO:root:[1,   474] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   475/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.3 ms)
INFO:root:[1,   475] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   476/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.3 ms)
INFO:root:[1,   476] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   477/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.4 ms)
INFO:root:[1,   477] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   478/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.4 ms)
INFO:root:[1,   478] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   479/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.28e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.5 ms)
INFO:root:[1,   479] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   480/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.5 ms)
INFO:root:[1,   480] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   481/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.5 ms)
INFO:root:[1,   481] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   482/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.6 ms)
INFO:root:[1,   482] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   483/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.7 ms)
INFO:root:[1,   483] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   484/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.7 ms)
INFO:root:[1,   484] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   485/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.8 ms)
INFO:root:[1,   485] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   486/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.9 ms)
INFO:root:[1,   486] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   487/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.9 ms)
INFO:root:[1,   487] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   488/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1154.9 ms)
INFO:root:[1,   488] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   489/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.0 ms)
INFO:root:[1,   489] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   490/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.1 ms)
INFO:root:[1,   490] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   491/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.2 ms)
INFO:root:[1,   491] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   492/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.2 ms)
INFO:root:[1,   492] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   493/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.3 ms)
INFO:root:[1,   493] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   494/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.4 ms)
INFO:root:[1,   494] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   495/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.4 ms)
INFO:root:[1,   495] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   496/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.5 ms)
INFO:root:[1,   496] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   497/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.5 ms)
INFO:root:[1,   497] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   498/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.5 ms)
INFO:root:[1,   498] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   499/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.6 ms)
INFO:root:[1,   499] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   500/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.27e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.6 ms)
INFO:root:[1,   500] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   501/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.7 ms)
INFO:root:[1,   501] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   502/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.8 ms)
INFO:root:[1,   502] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   503/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.8 ms)
INFO:root:[1,   503] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   504/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.9 ms)
INFO:root:[1,   504] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   505/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.9 ms)
INFO:root:[1,   505] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   506/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.9 ms)
INFO:root:[1,   506] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   507/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1155.9 ms)
INFO:root:[1,   507] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   508/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.0 ms)
INFO:root:[1,   508] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   509/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.1 ms)
INFO:root:[1,   509] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   510/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.1 ms)
INFO:root:[1,   510] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   511/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.2 ms)
INFO:root:[1,   511] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   512/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.3 ms)
INFO:root:[1,   512] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   513/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.3 ms)
INFO:root:[1,   513] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   514/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.4 ms)
INFO:root:[1,   514] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   515/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.4 ms)
INFO:root:[1,   515] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   516/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.5 ms)
INFO:root:[1,   516] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   517/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.5 ms)
INFO:root:[1,   517] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   518/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.6 ms)
INFO:root:[1,   518] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   519/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.6 ms)
INFO:root:[1,   519] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   520/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.7 ms)
INFO:root:[1,   520] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   521/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.8 ms)
INFO:root:[1,   521] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   522/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.26e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.8 ms)
INFO:root:[1,   522] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   523/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.9 ms)
INFO:root:[1,   523] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   524/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1156.9 ms)
INFO:root:[1,   524] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   525/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.0 ms)
INFO:root:[1,   525] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   526/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.0 ms)
INFO:root:[1,   526] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   527/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.1 ms)
INFO:root:[1,   527] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   528/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.1 ms)
INFO:root:[1,   528] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   529/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.2 ms)
INFO:root:[1,   529] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   530/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.3 ms)
INFO:root:[1,   530] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   531/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.3 ms)
INFO:root:[1,   531] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   532/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.4 ms)
INFO:root:[1,   532] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   533/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.5 ms)
INFO:root:[1,   533] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   534/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.5 ms)
INFO:root:[1,   534] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   535/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.6 ms)
INFO:root:[1,   535] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   536/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.7 ms)
INFO:root:[1,   536] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   537/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1157.8 ms)
INFO:root:[1,   537] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   538/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.2 ms)
INFO:root:[1,   538] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   539/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.2 ms)
INFO:root:[1,   539] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   540/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.3 ms)
INFO:root:[1,   540] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   541/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.3 ms)
INFO:root:[1,   541] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   542/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.4 ms)
INFO:root:[1,   542] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   543/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.25e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.4 ms)
INFO:root:[1,   543] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   544/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.5 ms)
INFO:root:[1,   544] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   545/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.5 ms)
INFO:root:[1,   545] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   546/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.6 ms)
INFO:root:[1,   546] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   547/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.6 ms)
INFO:root:[1,   547] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   548/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.7 ms)
INFO:root:[1,   548] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   549/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.7 ms)
INFO:root:[1,   549] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   550/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.8 ms)
INFO:root:[1,   550] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   551/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.8 ms)
INFO:root:[1,   551] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   552/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1158.9 ms)
INFO:root:[1,   552] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   553/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.0 ms)
INFO:root:[1,   553] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   554/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.0 ms)
INFO:root:[1,   554] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   555/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.1 ms)
INFO:root:[1,   555] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   556/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.1 ms)
INFO:root:[1,   556] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   557/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.2 ms)
INFO:root:[1,   557] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   558/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.2 ms)
INFO:root:[1,   558] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   559/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.3 ms)
INFO:root:[1,   559] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   560/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.4 ms)
INFO:root:[1,   560] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   561/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.4 ms)
INFO:root:[1,   561] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   562/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.5 ms)
INFO:root:[1,   562] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   563/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.5 ms)
INFO:root:[1,   563] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   564/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.24e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.6 ms)
INFO:root:[1,   564] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   565/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.6 ms)
INFO:root:[1,   565] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   566/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.7 ms)
INFO:root:[1,   566] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   567/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.7 ms)
INFO:root:[1,   567] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   568/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.8 ms)
INFO:root:[1,   568] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   569/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.8 ms)
INFO:root:[1,   569] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   570/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.9 ms)
INFO:root:[1,   570] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   571/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1159.9 ms)
INFO:root:[1,   571] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   572/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.0 ms)
INFO:root:[1,   572] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   573/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.0 ms)
INFO:root:[1,   573] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   574/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.1 ms)
INFO:root:[1,   574] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   575/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.2 ms)
INFO:root:[1,   575] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   576/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.2 ms)
INFO:root:[1,   576] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   577/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.3 ms)
INFO:root:[1,   577] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   578/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.4 ms)
INFO:root:[1,   578] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   579/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.4 ms)
INFO:root:[1,   579] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   580/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.5 ms)
INFO:root:[1,   580] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   581/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.6 ms)
INFO:root:[1,   581] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   582/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.7 ms)
INFO:root:[1,   582] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   583/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.8 ms)
INFO:root:[1,   583] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   584/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.9 ms)
INFO:root:[1,   584] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   585/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1160.9 ms)
INFO:root:[1,   585] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   586/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.23e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.0 ms)
INFO:root:[1,   586] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   587/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.1 ms)
INFO:root:[1,   587] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   588/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.2 ms)
INFO:root:[1,   588] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   589/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.2 ms)
INFO:root:[1,   589] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   590/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.3 ms)
INFO:root:[1,   590] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   591/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.4 ms)
INFO:root:[1,   591] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   592/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.4 ms)
INFO:root:[1,   592] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   593/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.5 ms)
INFO:root:[1,   593] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   594/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.5 ms)
INFO:root:[1,   594] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   595/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.6 ms)
INFO:root:[1,   595] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   596/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.7 ms)
INFO:root:[1,   596] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   597/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.8 ms)
INFO:root:[1,   597] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   598/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.8 ms)
INFO:root:[1,   598] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   599/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.9 ms)
INFO:root:[1,   599] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   600/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1161.9 ms)
INFO:root:[1,   600] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   601/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.0 ms)
INFO:root:[1,   601] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   602/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.0 ms)
INFO:root:[1,   602] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   603/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.1 ms)
INFO:root:[1,   603] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   604/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.1 ms)
INFO:root:[1,   604] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   605/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.2 ms)
INFO:root:[1,   605] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   606/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.3 ms)
INFO:root:[1,   606] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   607/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.22e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.3 ms)
INFO:root:[1,   607] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   608/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.4 ms)
INFO:root:[1,   608] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   609/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.5 ms)
INFO:root:[1,   609] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   610/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.5 ms)
INFO:root:[1,   610] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   611/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.6 ms)
INFO:root:[1,   611] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   612/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.7 ms)
INFO:root:[1,   612] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   613/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.7 ms)
INFO:root:[1,   613] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   614/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.8 ms)
INFO:root:[1,   614] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   615/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.9 ms)
INFO:root:[1,   615] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   616/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.9 ms)
INFO:root:[1,   616] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   617/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1162.9 ms)
INFO:root:[1,   617] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   618/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.0 ms)
INFO:root:[1,   618] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   619/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.0 ms)
INFO:root:[1,   619] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   620/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.1 ms)
INFO:root:[1,   620] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   621/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.2 ms)
INFO:root:[1,   621] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   622/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.2 ms)
INFO:root:[1,   622] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   623/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.3 ms)
INFO:root:[1,   623] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   624/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.4 ms)
INFO:root:[1,   624] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   625/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.4 ms)
INFO:root:[1,   625] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   626/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.5 ms)
INFO:root:[1,   626] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   627/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.6 ms)
INFO:root:[1,   627] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   628/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.21e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.7 ms)
INFO:root:[1,   628] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   629/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.7 ms)
INFO:root:[1,   629] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   630/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.8 ms)
INFO:root:[1,   630] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   631/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.8 ms)
INFO:root:[1,   631] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   632/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.9 ms)
INFO:root:[1,   632] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   633/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1163.9 ms)
INFO:root:[1,   633] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   634/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.0 ms)
INFO:root:[1,   634] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   635/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.1 ms)
INFO:root:[1,   635] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   636/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.1 ms)
INFO:root:[1,   636] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   637/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.2 ms)
INFO:root:[1,   637] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   638/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.3 ms)
INFO:root:[1,   638] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   639/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.3 ms)
INFO:root:[1,   639] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   640/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.4 ms)
INFO:root:[1,   640] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   641/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.4 ms)
INFO:root:[1,   641] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   642/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.5 ms)
INFO:root:[1,   642] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   643/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.5 ms)
INFO:root:[1,   643] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   644/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.6 ms)
INFO:root:[1,   644] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   645/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.6 ms)
INFO:root:[1,   645] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   646/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.6 ms)
INFO:root:[1,   646] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   647/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.6 ms)
INFO:root:[1,   647] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   648/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.7 ms)
INFO:root:[1,   648] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   649/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.8 ms)
INFO:root:[1,   649] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   650/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.20e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.9 ms)
INFO:root:[1,   650] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   651/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1164.9 ms)
INFO:root:[1,   651] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   652/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.0 ms)
INFO:root:[1,   652] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   653/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.0 ms)
INFO:root:[1,   653] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   654/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.1 ms)
INFO:root:[1,   654] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   655/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.2 ms)
INFO:root:[1,   655] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   656/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.2 ms)
INFO:root:[1,   656] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   657/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.3 ms)
INFO:root:[1,   657] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   658/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.3 ms)
INFO:root:[1,   658] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   659/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.4 ms)
INFO:root:[1,   659] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   660/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.5 ms)
INFO:root:[1,   660] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   661/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.5 ms)
INFO:root:[1,   661] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   662/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.6 ms)
INFO:root:[1,   662] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   663/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.7 ms)
INFO:root:[1,   663] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   664/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.7 ms)
INFO:root:[1,   664] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   665/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.8 ms)
INFO:root:[1,   665] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   666/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.8 ms)
INFO:root:[1,   666] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   667/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1165.9 ms)
INFO:root:[1,   667] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   668/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.0 ms)
INFO:root:[1,   668] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   669/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.1 ms)
INFO:root:[1,   669] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   670/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.2 ms)
INFO:root:[1,   670] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   671/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.19e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.2 ms)
INFO:root:[1,   671] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   672/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.3 ms)
INFO:root:[1,   672] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   673/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.4 ms)
INFO:root:[1,   673] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   674/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.4 ms)
INFO:root:[1,   674] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   675/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.5 ms)
INFO:root:[1,   675] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   676/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.5 ms)
INFO:root:[1,   676] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   677/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.6 ms)
INFO:root:[1,   677] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   678/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.7 ms)
INFO:root:[1,   678] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   679/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.7 ms)
INFO:root:[1,   679] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   680/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.8 ms)
INFO:root:[1,   680] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   681/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1166.9 ms)
INFO:root:[1,   681] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   682/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.0 ms)
INFO:root:[1,   682] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   683/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.0 ms)
INFO:root:[1,   683] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   684/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.1 ms)
INFO:root:[1,   684] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   685/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.1 ms)
INFO:root:[1,   685] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   686/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.2 ms)
INFO:root:[1,   686] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   687/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.2 ms)
INFO:root:[1,   687] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   688/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.3 ms)
INFO:root:[1,   688] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   689/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.4 ms)
INFO:root:[1,   689] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   690/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.4 ms)
INFO:root:[1,   690] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   691/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.5 ms)
INFO:root:[1,   691] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   692/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.18e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.5 ms)
INFO:root:[1,   692] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   693/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.6 ms)
INFO:root:[1,   693] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   694/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.6 ms)
INFO:root:[1,   694] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   695/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.7 ms)
INFO:root:[1,   695] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   696/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.7 ms)
INFO:root:[1,   696] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   697/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.8 ms)
INFO:root:[1,   697] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   698/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.9 ms)
INFO:root:[1,   698] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   699/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1167.9 ms)
INFO:root:[1,   699] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   700/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.0 ms)
INFO:root:[1,   700] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   701/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.1 ms)
INFO:root:[1,   701] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   702/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.2 ms)
INFO:root:[1,   702] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   703/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.2 ms)
INFO:root:[1,   703] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   704/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.3 ms)
INFO:root:[1,   704] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   705/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.3 ms)
INFO:root:[1,   705] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   706/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.4 ms)
INFO:root:[1,   706] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   707/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.4 ms)
INFO:root:[1,   707] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   708/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.5 ms)
INFO:root:[1,   708] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   709/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.6 ms)
INFO:root:[1,   709] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   710/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.6 ms)
INFO:root:[1,   710] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   711/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.7 ms)
INFO:root:[1,   711] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   712/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.8 ms)
INFO:root:[1,   712] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   713/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.8 ms)
INFO:root:[1,   713] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   714/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.17e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1168.9 ms)
INFO:root:[1,   714] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   715/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.0 ms)
INFO:root:[1,   715] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   716/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.1 ms)
INFO:root:[1,   716] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   717/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.2 ms)
INFO:root:[1,   717] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   718/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.3 ms)
INFO:root:[1,   718] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   719/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.3 ms)
INFO:root:[1,   719] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   720/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.4 ms)
INFO:root:[1,   720] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   721/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.5 ms)
INFO:root:[1,   721] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   722/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.5 ms)
INFO:root:[1,   722] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   723/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.6 ms)
INFO:root:[1,   723] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   724/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.6 ms)
INFO:root:[1,   724] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   725/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.7 ms)
INFO:root:[1,   725] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   726/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.8 ms)
INFO:root:[1,   726] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   727/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.9 ms)
INFO:root:[1,   727] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   728/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1169.9 ms)
INFO:root:[1,   728] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   729/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.0 ms)
INFO:root:[1,   729] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   730/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.0 ms)
INFO:root:[1,   730] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   731/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.1 ms)
INFO:root:[1,   731] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   732/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.2 ms)
INFO:root:[1,   732] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   733/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.2 ms)
INFO:root:[1,   733] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   734/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.2 ms)
INFO:root:[1,   734] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   735/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.16e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.3 ms)
INFO:root:[1,   735] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   736/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.4 ms)
INFO:root:[1,   736] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   737/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.4 ms)
INFO:root:[1,   737] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   738/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.5 ms)
INFO:root:[1,   738] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   739/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.5 ms)
INFO:root:[1,   739] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   740/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.6 ms)
INFO:root:[1,   740] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   741/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.7 ms)
INFO:root:[1,   741] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   742/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.8 ms)
INFO:root:[1,   742] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   743/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.8 ms)
INFO:root:[1,   743] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   744/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1170.9 ms)
INFO:root:[1,   744] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   745/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.0 ms)
INFO:root:[1,   745] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   746/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.0 ms)
INFO:root:[1,   746] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   747/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.1 ms)
INFO:root:[1,   747] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   748/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.2 ms)
INFO:root:[1,   748] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   749/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.2 ms)
INFO:root:[1,   749] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   750/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.3 ms)
INFO:root:[1,   750] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   751/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.4 ms)
INFO:root:[1,   751] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   752/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.4 ms)
INFO:root:[1,   752] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   753/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.5 ms)
INFO:root:[1,   753] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   754/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.5 ms)
INFO:root:[1,   754] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   755/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.6 ms)
INFO:root:[1,   755] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   756/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.15e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.7 ms)
INFO:root:[1,   756] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   757/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.8 ms)
INFO:root:[1,   757] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   758/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1171.9 ms)
INFO:root:[1,   758] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   759/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.0 ms)
INFO:root:[1,   759] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   760/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.0 ms)
INFO:root:[1,   760] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   761/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.2 ms)
INFO:root:[1,   761] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   762/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.2 ms)
INFO:root:[1,   762] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   763/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.3 ms)
INFO:root:[1,   763] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   764/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.3 ms)
INFO:root:[1,   764] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   765/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.4 ms)
INFO:root:[1,   765] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   766/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.5 ms)
INFO:root:[1,   766] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   767/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.5 ms)
INFO:root:[1,   767] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   768/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.6 ms)
INFO:root:[1,   768] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   769/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.7 ms)
INFO:root:[1,   769] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   770/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.7 ms)
INFO:root:[1,   770] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   771/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.8 ms)
INFO:root:[1,   771] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   772/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.9 ms)
INFO:root:[1,   772] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   773/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1172.9 ms)
INFO:root:[1,   773] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   774/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.0 ms)
INFO:root:[1,   774] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   775/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.1 ms)
INFO:root:[1,   775] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   776/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.1 ms)
INFO:root:[1,   776] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   777/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.2 ms)
INFO:root:[1,   777] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   778/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.14e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.3 ms)
INFO:root:[1,   778] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   779/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.3 ms)
INFO:root:[1,   779] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   780/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.4 ms)
INFO:root:[1,   780] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   781/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.5 ms)
INFO:root:[1,   781] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   782/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.5 ms)
INFO:root:[1,   782] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   783/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.6 ms)
INFO:root:[1,   783] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   784/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.6 ms)
INFO:root:[1,   784] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   785/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.7 ms)
INFO:root:[1,   785] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   786/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.8 ms)
INFO:root:[1,   786] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   787/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.8 ms)
INFO:root:[1,   787] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   788/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1173.9 ms)
INFO:root:[1,   788] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   789/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.0 ms)
INFO:root:[1,   789] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   790/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.0 ms)
INFO:root:[1,   790] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   791/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.1 ms)
INFO:root:[1,   791] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   792/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.2 ms)
INFO:root:[1,   792] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   793/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.2 ms)
INFO:root:[1,   793] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   794/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.3 ms)
INFO:root:[1,   794] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   795/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.4 ms)
INFO:root:[1,   795] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   796/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.4 ms)
INFO:root:[1,   796] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   797/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.5 ms)
INFO:root:[1,   797] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   798/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.6 ms)
INFO:root:[1,   798] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   799/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.13e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.6 ms)
INFO:root:[1,   799] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   800/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.7 ms)
INFO:root:[1,   800] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   801/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.8 ms)
INFO:root:[1,   801] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   802/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.9 ms)
INFO:root:[1,   802] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   803/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1174.9 ms)
INFO:root:[1,   803] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   804/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.0 ms)
INFO:root:[1,   804] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   805/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.1 ms)
INFO:root:[1,   805] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   806/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.2 ms)
INFO:root:[1,   806] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   807/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.3 ms)
INFO:root:[1,   807] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   808/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.3 ms)
INFO:root:[1,   808] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   809/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.4 ms)
INFO:root:[1,   809] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   810/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.4 ms)
INFO:root:[1,   810] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   811/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.5 ms)
INFO:root:[1,   811] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   812/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.6 ms)
INFO:root:[1,   812] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   813/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.6 ms)
INFO:root:[1,   813] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   814/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.7 ms)
INFO:root:[1,   814] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   815/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.8 ms)
INFO:root:[1,   815] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   816/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.8 ms)
INFO:root:[1,   816] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   817/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1175.9 ms)
INFO:root:[1,   817] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   818/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.0 ms)
INFO:root:[1,   818] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   819/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.0 ms)
INFO:root:[1,   819] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   820/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.12e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.1 ms)
INFO:root:[1,   820] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   821/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.2 ms)
INFO:root:[1,   821] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   822/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.2 ms)
INFO:root:[1,   822] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   823/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.3 ms)
INFO:root:[1,   823] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   824/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.3 ms)
INFO:root:[1,   824] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   825/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.4 ms)
INFO:root:[1,   825] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   826/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.5 ms)
INFO:root:[1,   826] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   827/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.5 ms)
INFO:root:[1,   827] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   828/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.6 ms)
INFO:root:[1,   828] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   829/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.7 ms)
INFO:root:[1,   829] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   830/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.7 ms)
INFO:root:[1,   830] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   831/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.8 ms)
INFO:root:[1,   831] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   832/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.9 ms)
INFO:root:[1,   832] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   833/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1176.9 ms)
INFO:root:[1,   833] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   834/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.0 ms)
INFO:root:[1,   834] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   835/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.0 ms)
INFO:root:[1,   835] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   836/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.1 ms)
INFO:root:[1,   836] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   837/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.2 ms)
INFO:root:[1,   837] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   838/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.2 ms)
INFO:root:[1,   838] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   839/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.3 ms)
INFO:root:[1,   839] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   840/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.4 ms)
INFO:root:[1,   840] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   841/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.4 ms)
INFO:root:[1,   841] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   842/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.11e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.5 ms)
INFO:root:[1,   842] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   843/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.6 ms)
INFO:root:[1,   843] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   844/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.6 ms)
INFO:root:[1,   844] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   845/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.7 ms)
INFO:root:[1,   845] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   846/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.8 ms)
INFO:root:[1,   846] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   847/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1177.9 ms)
INFO:root:[1,   847] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   848/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.0 ms)
INFO:root:[1,   848] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   849/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.1 ms)
INFO:root:[1,   849] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   850/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.1 ms)
INFO:root:[1,   850] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   851/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.2 ms)
INFO:root:[1,   851] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   852/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.2 ms)
INFO:root:[1,   852] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   853/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.3 ms)
INFO:root:[1,   853] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   854/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.4 ms)
INFO:root:[1,   854] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   855/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.4 ms)
INFO:root:[1,   855] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   856/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.5 ms)
INFO:root:[1,   856] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   857/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.6 ms)
INFO:root:[1,   857] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   858/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.6 ms)
INFO:root:[1,   858] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   859/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.7 ms)
INFO:root:[1,   859] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   860/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.7 ms)
INFO:root:[1,   860] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   861/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.8 ms)
INFO:root:[1,   861] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   862/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1178.9 ms)
INFO:root:[1,   862] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   863/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.10e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.0 ms)
INFO:root:[1,   863] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   864/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.0 ms)
INFO:root:[1,   864] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   865/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.1 ms)
INFO:root:[1,   865] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   866/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.2 ms)
INFO:root:[1,   866] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   867/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.2 ms)
INFO:root:[1,   867] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   868/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.3 ms)
INFO:root:[1,   868] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   869/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.4 ms)
INFO:root:[1,   869] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   870/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.4 ms)
INFO:root:[1,   870] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   871/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.5 ms)
INFO:root:[1,   871] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   872/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.6 ms)
INFO:root:[1,   872] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   873/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.6 ms)
INFO:root:[1,   873] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   874/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.7 ms)
INFO:root:[1,   874] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   875/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.7 ms)
INFO:root:[1,   875] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   876/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.8 ms)
INFO:root:[1,   876] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   877/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.8 ms)
INFO:root:[1,   877] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   878/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1179.9 ms)
INFO:root:[1,   878] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   879/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.0 ms)
INFO:root:[1,   879] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   880/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.1 ms)
INFO:root:[1,   880] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   881/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.1 ms)
INFO:root:[1,   881] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   882/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.2 ms)
INFO:root:[1,   882] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   883/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.3 ms)
INFO:root:[1,   883] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   884/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.4 ms)
INFO:root:[1,   884] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   885/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.09e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.4 ms)
INFO:root:[1,   885] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   886/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.5 ms)
INFO:root:[1,   886] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   887/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.6 ms)
INFO:root:[1,   887] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   888/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.7 ms)
INFO:root:[1,   888] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   889/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.8 ms)
INFO:root:[1,   889] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   890/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.8 ms)
INFO:root:[1,   890] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   891/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1180.9 ms)
INFO:root:[1,   891] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   892/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.0 ms)
INFO:root:[1,   892] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   893/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.1 ms)
INFO:root:[1,   893] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   894/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.1 ms)
INFO:root:[1,   894] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   895/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.2 ms)
INFO:root:[1,   895] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   896/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.3 ms)
INFO:root:[1,   896] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   897/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.3 ms)
INFO:root:[1,   897] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   898/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.4 ms)
INFO:root:[1,   898] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   899/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.5 ms)
INFO:root:[1,   899] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   900/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.5 ms)
INFO:root:[1,   900] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   901/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.6 ms)
INFO:root:[1,   901] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   902/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.6 ms)
INFO:root:[1,   902] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   903/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.7 ms)
INFO:root:[1,   903] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   904/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.7 ms)
INFO:root:[1,   904] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   905/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.8 ms)
INFO:root:[1,   905] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   906/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.08e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.9 ms)
INFO:root:[1,   906] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   907/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1181.9 ms)
INFO:root:[1,   907] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   908/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.0 ms)
INFO:root:[1,   908] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   909/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.1 ms)
INFO:root:[1,   909] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   910/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.1 ms)
INFO:root:[1,   910] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   911/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.2 ms)
INFO:root:[1,   911] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   912/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.3 ms)
INFO:root:[1,   912] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   913/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.3 ms)
INFO:root:[1,   913] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   914/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.4 ms)
INFO:root:[1,   914] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   915/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.4 ms)
INFO:root:[1,   915] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   916/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.5 ms)
INFO:root:[1,   916] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   917/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.5 ms)
INFO:root:[1,   917] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   918/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.6 ms)
INFO:root:[1,   918] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   919/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.7 ms)
INFO:root:[1,   919] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   920/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.8 ms)
INFO:root:[1,   920] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   921/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.9 ms)
INFO:root:[1,   921] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   922/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1182.9 ms)
INFO:root:[1,   922] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   923/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.0 ms)
INFO:root:[1,   923] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   924/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.1 ms)
INFO:root:[1,   924] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   925/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.1 ms)
INFO:root:[1,   925] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   926/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.2 ms)
INFO:root:[1,   926] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   927/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.07e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.2 ms)
INFO:root:[1,   927] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   928/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.3 ms)
INFO:root:[1,   928] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   929/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.4 ms)
INFO:root:[1,   929] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   930/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.4 ms)
INFO:root:[1,   930] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   931/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.5 ms)
INFO:root:[1,   931] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   932/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.6 ms)
INFO:root:[1,   932] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   933/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.7 ms)
INFO:root:[1,   933] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   934/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.8 ms)
INFO:root:[1,   934] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   935/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.9 ms)
INFO:root:[1,   935] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   936/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1183.9 ms)
INFO:root:[1,   936] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   937/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.0 ms)
INFO:root:[1,   937] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   938/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.1 ms)
INFO:root:[1,   938] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   939/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.1 ms)
INFO:root:[1,   939] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   940/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.2 ms)
INFO:root:[1,   940] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   941/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.2 ms)
INFO:root:[1,   941] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   942/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.3 ms)
INFO:root:[1,   942] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   943/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.4 ms)
INFO:root:[1,   943] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   944/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.4 ms)
INFO:root:[1,   944] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   945/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.5 ms)
INFO:root:[1,   945] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   946/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.5 ms)
INFO:root:[1,   946] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   947/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.6 ms)
INFO:root:[1,   947] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   948/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.7 ms)
INFO:root:[1,   948] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   949/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.06e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.7 ms)
INFO:root:[1,   949] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   950/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.8 ms)
INFO:root:[1,   950] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   951/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.8 ms)
INFO:root:[1,   951] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   952/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.9 ms)
INFO:root:[1,   952] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   953/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1184.9 ms)
INFO:root:[1,   953] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   954/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.0 ms)
INFO:root:[1,   954] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   955/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.1 ms)
INFO:root:[1,   955] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   956/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.1 ms)
INFO:root:[1,   956] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   957/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.2 ms)
INFO:root:[1,   957] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   958/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.2 ms)
INFO:root:[1,   958] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   959/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.3 ms)
INFO:root:[1,   959] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   960/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.4 ms)
INFO:root:[1,   960] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   961/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.4 ms)
INFO:root:[1,   961] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   962/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.5 ms)
INFO:root:[1,   962] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   963/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.6 ms)
INFO:root:[1,   963] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   964/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.6 ms)
INFO:root:[1,   964] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   965/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.7 ms)
INFO:root:[1,   965] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   966/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.8 ms)
INFO:root:[1,   966] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   967/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.8 ms)
INFO:root:[1,   967] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   968/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1185.9 ms)
INFO:root:[1,   968] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   969/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.0 ms)
INFO:root:[1,   969] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   970/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.05e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.0 ms)
INFO:root:[1,   970] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   971/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.1 ms)
INFO:root:[1,   971] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   972/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.2 ms)
INFO:root:[1,   972] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   973/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.2 ms)
INFO:root:[1,   973] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   974/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.3 ms)
INFO:root:[1,   974] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   975/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.4 ms)
INFO:root:[1,   975] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   976/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.5 ms)
INFO:root:[1,   976] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   977/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.6 ms)
INFO:root:[1,   977] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   978/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.7 ms)
INFO:root:[1,   978] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   979/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.8 ms)
INFO:root:[1,   979] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   980/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.8 ms)
INFO:root:[1,   980] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   981/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1186.9 ms)
INFO:root:[1,   981] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   982/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.0 ms)
INFO:root:[1,   982] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   983/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.0 ms)
INFO:root:[1,   983] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   984/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.1 ms)
INFO:root:[1,   984] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   985/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.2 ms)
INFO:root:[1,   985] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   986/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.2 ms)
INFO:root:[1,   986] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   987/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.3 ms)
INFO:root:[1,   987] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   988/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.4 ms)
INFO:root:[1,   988] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   989/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.4 ms)
INFO:root:[1,   989] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   990/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.5 ms)
INFO:root:[1,   990] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   991/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.04e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.6 ms)
INFO:root:[1,   991] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   992/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.6 ms)
INFO:root:[1,   992] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   993/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.7 ms)
INFO:root:[1,   993] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   994/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.7 ms)
INFO:root:[1,   994] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   995/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.8 ms)
INFO:root:[1,   995] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   996/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.9 ms)
INFO:root:[1,   996] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   997/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1187.9 ms)
INFO:root:[1,   997] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   998/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.0 ms)
INFO:root:[1,   998] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,   999/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.0 ms)
INFO:root:[1,   999] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1000/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.1 ms)
INFO:root:[1,  1000] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1001/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.1 ms)
INFO:root:[1,  1001] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1002/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.2 ms)
INFO:root:[1,  1002] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1003/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.2 ms)
INFO:root:[1,  1003] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1004/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.3 ms)
INFO:root:[1,  1004] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1005/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.4 ms)
INFO:root:[1,  1005] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1006/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.4 ms)
INFO:root:[1,  1006] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1007/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.5 ms)
INFO:root:[1,  1007] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1008/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.5 ms)
INFO:root:[1,  1008] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1009/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.6 ms)
INFO:root:[1,  1009] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1010/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.7 ms)
INFO:root:[1,  1010] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1011/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.8 ms)
INFO:root:[1,  1011] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1012/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.8 ms)
INFO:root:[1,  1012] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1013/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.03e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1188.9 ms)
INFO:root:[1,  1013] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1014/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.0 ms)
INFO:root:[1,  1014] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1015/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.0 ms)
INFO:root:[1,  1015] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1016/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.1 ms)
INFO:root:[1,  1016] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1017/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.1 ms)
INFO:root:[1,  1017] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1018/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.2 ms)
INFO:root:[1,  1018] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1019/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.3 ms)
INFO:root:[1,  1019] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1020/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.4 ms)
INFO:root:[1,  1020] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1021/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.5 ms)
INFO:root:[1,  1021] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1022/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.6 ms)
INFO:root:[1,  1022] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1023/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.7 ms)
INFO:root:[1,  1023] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1024/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.8 ms)
INFO:root:[1,  1024] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1025/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1189.9 ms)
INFO:root:[1,  1025] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1026/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.0 ms)
INFO:root:[1,  1026] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1027/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.0 ms)
INFO:root:[1,  1027] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1028/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.1 ms)
INFO:root:[1,  1028] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1029/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.1 ms)
INFO:root:[1,  1029] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1030/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.2 ms)
INFO:root:[1,  1030] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1031/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.3 ms)
INFO:root:[1,  1031] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1032/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.4 ms)
INFO:root:[1,  1032] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1033/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.4 ms)
INFO:root:[1,  1033] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1034/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.02e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.5 ms)
INFO:root:[1,  1034] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1035/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.5 ms)
INFO:root:[1,  1035] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1036/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.6 ms)
INFO:root:[1,  1036] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1037/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.7 ms)
INFO:root:[1,  1037] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1038/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.7 ms)
INFO:root:[1,  1038] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1039/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.8 ms)
INFO:root:[1,  1039] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1040/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.8 ms)
INFO:root:[1,  1040] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1041/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1190.9 ms)
INFO:root:[1,  1041] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1042/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.0 ms)
INFO:root:[1,  1042] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1043/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.1 ms)
INFO:root:[1,  1043] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1044/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.1 ms)
INFO:root:[1,  1044] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1045/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.2 ms)
INFO:root:[1,  1045] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1046/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.3 ms)
INFO:root:[1,  1046] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1047/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.3 ms)
INFO:root:[1,  1047] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1048/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.4 ms)
INFO:root:[1,  1048] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1049/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.5 ms)
INFO:root:[1,  1049] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1050/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.59e-04][mem: 6.87e+04] (1191.5 ms)
INFO:root:[1,  1050] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1051/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1191.6 ms)
INFO:root:[1,  1051] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1052/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1191.7 ms)
INFO:root:[1,  1052] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1053/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1191.8 ms)
INFO:root:[1,  1053] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1054/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1191.8 ms)
INFO:root:[1,  1054] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1055/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.01e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1191.9 ms)
INFO:root:[1,  1055] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1056/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.0 ms)
INFO:root:[1,  1056] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1057/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.0 ms)
INFO:root:[1,  1057] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1058/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.1 ms)
INFO:root:[1,  1058] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1059/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.2 ms)
INFO:root:[1,  1059] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1060/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.2 ms)
INFO:root:[1,  1060] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1061/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.3 ms)
INFO:root:[1,  1061] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1062/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.4 ms)
INFO:root:[1,  1062] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1063/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.5 ms)
INFO:root:[1,  1063] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1064/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.6 ms)
INFO:root:[1,  1064] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1065/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.7 ms)
INFO:root:[1,  1065] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1066/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.8 ms)
INFO:root:[1,  1066] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1067/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1192.9 ms)
INFO:root:[1,  1067] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1068/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.0 ms)
INFO:root:[1,  1068] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1069/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.0 ms)
INFO:root:[1,  1069] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1070/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.1 ms)
INFO:root:[1,  1070] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1071/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.2 ms)
INFO:root:[1,  1071] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1072/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.2 ms)
INFO:root:[1,  1072] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1073/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.3 ms)
INFO:root:[1,  1073] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1074/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.3 ms)
INFO:root:[1,  1074] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1075/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.4 ms)
INFO:root:[1,  1075] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1076/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.5 ms)
INFO:root:[1,  1076] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1077/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 8.00e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.5 ms)
INFO:root:[1,  1077] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1078/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.6 ms)
INFO:root:[1,  1078] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1079/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.7 ms)
INFO:root:[1,  1079] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1080/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.8 ms)
INFO:root:[1,  1080] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1081/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.8 ms)
INFO:root:[1,  1081] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1082/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.9 ms)
INFO:root:[1,  1082] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1083/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1193.9 ms)
INFO:root:[1,  1083] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1084/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.0 ms)
INFO:root:[1,  1084] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1085/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.1 ms)
INFO:root:[1,  1085] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1086/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.2 ms)
INFO:root:[1,  1086] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1087/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.2 ms)
INFO:root:[1,  1087] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1088/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.3 ms)
INFO:root:[1,  1088] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1089/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.4 ms)
INFO:root:[1,  1089] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1090/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.5 ms)
INFO:root:[1,  1090] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1091/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.6 ms)
INFO:root:[1,  1091] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1092/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.6 ms)
INFO:root:[1,  1092] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1093/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.7 ms)
INFO:root:[1,  1093] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1094/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.8 ms)
INFO:root:[1,  1094] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1095/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.9 ms)
INFO:root:[1,  1095] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1096/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1194.9 ms)
INFO:root:[1,  1096] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1097/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.0 ms)
INFO:root:[1,  1097] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1098/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.99e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.1 ms)
INFO:root:[1,  1098] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1099/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.2 ms)
INFO:root:[1,  1099] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1100/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.2 ms)
INFO:root:[1,  1100] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1101/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.3 ms)
INFO:root:[1,  1101] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1102/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.3 ms)
INFO:root:[1,  1102] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1103/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.4 ms)
INFO:root:[1,  1103] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1104/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.5 ms)
INFO:root:[1,  1104] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1105/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.5 ms)
INFO:root:[1,  1105] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1106/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.6 ms)
INFO:root:[1,  1106] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1107/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.7 ms)
INFO:root:[1,  1107] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1108/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.8 ms)
INFO:root:[1,  1108] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1109/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1195.9 ms)
INFO:root:[1,  1109] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1110/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.0 ms)
INFO:root:[1,  1110] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1111/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.0 ms)
INFO:root:[1,  1111] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1112/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.1 ms)
INFO:root:[1,  1112] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1113/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.2 ms)
INFO:root:[1,  1113] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1114/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.3 ms)
INFO:root:[1,  1114] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1115/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.4 ms)
INFO:root:[1,  1115] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1116/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.5 ms)
INFO:root:[1,  1116] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1117/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.5 ms)
INFO:root:[1,  1117] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1118/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.6 ms)
INFO:root:[1,  1118] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1119/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.98e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.6 ms)
INFO:root:[1,  1119] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1120/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.7 ms)
INFO:root:[1,  1120] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1121/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.8 ms)
INFO:root:[1,  1121] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1122/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.8 ms)
INFO:root:[1,  1122] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1123/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1196.9 ms)
INFO:root:[1,  1123] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1124/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.0 ms)
INFO:root:[1,  1124] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1125/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.0 ms)
INFO:root:[1,  1125] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1126/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.1 ms)
INFO:root:[1,  1126] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1127/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.1 ms)
INFO:root:[1,  1127] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1128/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.2 ms)
INFO:root:[1,  1128] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1129/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.3 ms)
INFO:root:[1,  1129] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1130/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.3 ms)
INFO:root:[1,  1130] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1131/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.4 ms)
INFO:root:[1,  1131] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1132/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.4 ms)
INFO:root:[1,  1132] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1133/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.5 ms)
INFO:root:[1,  1133] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1134/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.6 ms)
INFO:root:[1,  1134] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1135/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.6 ms)
INFO:root:[1,  1135] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1136/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.7 ms)
INFO:root:[1,  1136] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1137/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.8 ms)
INFO:root:[1,  1137] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1138/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.9 ms)
INFO:root:[1,  1138] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1139/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1197.9 ms)
INFO:root:[1,  1139] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1140/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.0 ms)
INFO:root:[1,  1140] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1141/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.97e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.0 ms)
INFO:root:[1,  1141] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1142/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.1 ms)
INFO:root:[1,  1142] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1143/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.2 ms)
INFO:root:[1,  1143] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1144/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.2 ms)
INFO:root:[1,  1144] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1145/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.3 ms)
INFO:root:[1,  1145] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1146/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.4 ms)
INFO:root:[1,  1146] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1147/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.4 ms)
INFO:root:[1,  1147] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1148/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.5 ms)
INFO:root:[1,  1148] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1149/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.6 ms)
INFO:root:[1,  1149] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1150/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.7 ms)
INFO:root:[1,  1150] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1151/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.8 ms)
INFO:root:[1,  1151] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1152/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1198.9 ms)
INFO:root:[1,  1152] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1153/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.0 ms)
INFO:root:[1,  1153] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1154/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.0 ms)
INFO:root:[1,  1154] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1155/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.1 ms)
INFO:root:[1,  1155] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1156/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.2 ms)
INFO:root:[1,  1156] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1157/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.3 ms)
INFO:root:[1,  1157] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1158/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.4 ms)
INFO:root:[1,  1158] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1159/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.5 ms)
INFO:root:[1,  1159] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1160/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.6 ms)
INFO:root:[1,  1160] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1161/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.6 ms)
INFO:root:[1,  1161] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1162/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.96e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.7 ms)
INFO:root:[1,  1162] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1163/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.8 ms)
INFO:root:[1,  1163] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1164/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1199.9 ms)
INFO:root:[1,  1164] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1165/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.0 ms)
INFO:root:[1,  1165] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1166/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.0 ms)
INFO:root:[1,  1166] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1167/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.1 ms)
INFO:root:[1,  1167] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1168/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.2 ms)
INFO:root:[1,  1168] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1169/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.2 ms)
INFO:root:[1,  1169] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1170/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.3 ms)
INFO:root:[1,  1170] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1171/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.4 ms)
INFO:root:[1,  1171] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1172/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.4 ms)
INFO:root:[1,  1172] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1173/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.5 ms)
INFO:root:[1,  1173] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1174/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.6 ms)
INFO:root:[1,  1174] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1175/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.7 ms)
INFO:root:[1,  1175] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1176/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.8 ms)
INFO:root:[1,  1176] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1177/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.9 ms)
INFO:root:[1,  1177] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1178/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1200.9 ms)
INFO:root:[1,  1178] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1179/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.0 ms)
INFO:root:[1,  1179] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1180/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.0 ms)
INFO:root:[1,  1180] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1181/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.1 ms)
INFO:root:[1,  1181] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1182/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.2 ms)
INFO:root:[1,  1182] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1183/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.95e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.2 ms)
INFO:root:[1,  1183] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1184/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.3 ms)
INFO:root:[1,  1184] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1185/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.4 ms)
INFO:root:[1,  1185] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1186/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.4 ms)
INFO:root:[1,  1186] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1187/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.5 ms)
INFO:root:[1,  1187] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1188/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.6 ms)
INFO:root:[1,  1188] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1189/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.7 ms)
INFO:root:[1,  1189] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1190/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.8 ms)
INFO:root:[1,  1190] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1191/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.8 ms)
INFO:root:[1,  1191] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1192/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1201.9 ms)
INFO:root:[1,  1192] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1193/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.0 ms)
INFO:root:[1,  1193] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1194/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.1 ms)
INFO:root:[1,  1194] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1195/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.2 ms)
INFO:root:[1,  1195] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1196/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.3 ms)
INFO:root:[1,  1196] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1197/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.3 ms)
INFO:root:[1,  1197] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1198/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.4 ms)
INFO:root:[1,  1198] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1199/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.4 ms)
INFO:root:[1,  1199] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1200/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.5 ms)
INFO:root:[1,  1200] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1201/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.5 ms)
INFO:root:[1,  1201] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1202/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.6 ms)
INFO:root:[1,  1202] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1203/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.7 ms)
INFO:root:[1,  1203] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1204/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.7 ms)
INFO:root:[1,  1204] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1205/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.94e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.8 ms)
INFO:root:[1,  1205] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1206/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.9 ms)
INFO:root:[1,  1206] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1207/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1202.9 ms)
INFO:root:[1,  1207] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1208/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.0 ms)
INFO:root:[1,  1208] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1209/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.0 ms)
INFO:root:[1,  1209] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1210/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.1 ms)
INFO:root:[1,  1210] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1211/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.1 ms)
INFO:root:[1,  1211] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1212/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.2 ms)
INFO:root:[1,  1212] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1213/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.3 ms)
INFO:root:[1,  1213] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1214/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.4 ms)
INFO:root:[1,  1214] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1215/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.4 ms)
INFO:root:[1,  1215] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1216/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.5 ms)
INFO:root:[1,  1216] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1217/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.6 ms)
INFO:root:[1,  1217] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1218/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.7 ms)
INFO:root:[1,  1218] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1219/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.8 ms)
INFO:root:[1,  1219] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1220/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.8 ms)
INFO:root:[1,  1220] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1221/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1203.9 ms)
INFO:root:[1,  1221] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1222/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.0 ms)
INFO:root:[1,  1222] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1223/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.1 ms)
INFO:root:[1,  1223] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1224/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.2 ms)
INFO:root:[1,  1224] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1225/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.3 ms)
INFO:root:[1,  1225] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1226/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.93e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.3 ms)
INFO:root:[1,  1226] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1227/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.4 ms)
INFO:root:[1,  1227] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1228/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.5 ms)
INFO:root:[1,  1228] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1229/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.5 ms)
INFO:root:[1,  1229] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1230/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.6 ms)
INFO:root:[1,  1230] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1231/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.7 ms)
INFO:root:[1,  1231] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1232/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.7 ms)
INFO:root:[1,  1232] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1233/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.8 ms)
INFO:root:[1,  1233] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1234/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1204.9 ms)
INFO:root:[1,  1234] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1235/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.0 ms)
INFO:root:[1,  1235] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1236/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.0 ms)
INFO:root:[1,  1236] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1237/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.1 ms)
INFO:root:[1,  1237] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1238/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.2 ms)
INFO:root:[1,  1238] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1239/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.3 ms)
INFO:root:[1,  1239] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1240/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.3 ms)
INFO:root:[1,  1240] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1241/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.4 ms)
INFO:root:[1,  1241] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1242/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.5 ms)
INFO:root:[1,  1242] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1243/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.6 ms)
INFO:root:[1,  1243] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1244/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.6 ms)
INFO:root:[1,  1244] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1245/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.7 ms)
INFO:root:[1,  1245] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1246/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.7 ms)
INFO:root:[1,  1246] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1247/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.92e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.8 ms)
INFO:root:[1,  1247] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1248/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.9 ms)
INFO:root:[1,  1248] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1249/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1205.9 ms)
INFO:root:[1,  1249] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1250/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.0 ms)
INFO:root:[1,  1250] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1251/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.1 ms)
INFO:root:[1,  1251] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1252/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.1 ms)
INFO:root:[1,  1252] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1253/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.2 ms)
INFO:root:[1,  1253] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1254/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.2 ms)
INFO:root:[1,  1254] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1255/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.3 ms)
INFO:root:[1,  1255] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1256/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.4 ms)
INFO:root:[1,  1256] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1257/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.5 ms)
INFO:root:[1,  1257] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1258/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.6 ms)
INFO:root:[1,  1258] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1259/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.6 ms)
INFO:root:[1,  1259] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1260/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.7 ms)
INFO:root:[1,  1260] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1261/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.8 ms)
INFO:root:[1,  1261] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1262/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.9 ms)
INFO:root:[1,  1262] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1263/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1206.9 ms)
INFO:root:[1,  1263] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1264/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.0 ms)
INFO:root:[1,  1264] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1265/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.1 ms)
INFO:root:[1,  1265] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1266/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.1 ms)
INFO:root:[1,  1266] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1267/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.2 ms)
INFO:root:[1,  1267] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1268/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.3 ms)
INFO:root:[1,  1268] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1269/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.91e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.4 ms)
INFO:root:[1,  1269] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1270/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.4 ms)
INFO:root:[1,  1270] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1271/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.5 ms)
INFO:root:[1,  1271] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1272/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.6 ms)
INFO:root:[1,  1272] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1273/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.6 ms)
INFO:root:[1,  1273] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1274/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.7 ms)
INFO:root:[1,  1274] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1275/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.8 ms)
INFO:root:[1,  1275] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1276/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1207.9 ms)
INFO:root:[1,  1276] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1277/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.0 ms)
INFO:root:[1,  1277] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1278/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.0 ms)
INFO:root:[1,  1278] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1279/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.1 ms)
INFO:root:[1,  1279] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1280/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.2 ms)
INFO:root:[1,  1280] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1281/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.3 ms)
INFO:root:[1,  1281] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1282/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.4 ms)
INFO:root:[1,  1282] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1283/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.4 ms)
INFO:root:[1,  1283] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1284/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.5 ms)
INFO:root:[1,  1284] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1285/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.6 ms)
INFO:root:[1,  1285] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1286/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.7 ms)
INFO:root:[1,  1286] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1287/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.7 ms)
INFO:root:[1,  1287] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1288/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.8 ms)
INFO:root:[1,  1288] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1289/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.9 ms)
INFO:root:[1,  1289] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1290/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.90e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1208.9 ms)
INFO:root:[1,  1290] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1291/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.0 ms)
INFO:root:[1,  1291] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1292/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.1 ms)
INFO:root:[1,  1292] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1293/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.1 ms)
INFO:root:[1,  1293] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1294/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.2 ms)
INFO:root:[1,  1294] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1295/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.3 ms)
INFO:root:[1,  1295] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1296/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.3 ms)
INFO:root:[1,  1296] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1297/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.4 ms)
INFO:root:[1,  1297] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1298/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.4 ms)
INFO:root:[1,  1298] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1299/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.5 ms)
INFO:root:[1,  1299] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1300/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.6 ms)
INFO:root:[1,  1300] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1301/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.7 ms)
INFO:root:[1,  1301] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1302/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.7 ms)
INFO:root:[1,  1302] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1303/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.8 ms)
INFO:root:[1,  1303] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1304/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1209.9 ms)
INFO:root:[1,  1304] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1305/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.0 ms)
INFO:root:[1,  1305] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1306/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.0 ms)
INFO:root:[1,  1306] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1307/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.1 ms)
INFO:root:[1,  1307] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1308/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.2 ms)
INFO:root:[1,  1308] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1309/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.3 ms)
INFO:root:[1,  1309] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1310/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.3 ms)
INFO:root:[1,  1310] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1311/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.4 ms)
INFO:root:[1,  1311] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1312/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.89e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.5 ms)
INFO:root:[1,  1312] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1313/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.5 ms)
INFO:root:[1,  1313] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1314/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.6 ms)
INFO:root:[1,  1314] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1315/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.7 ms)
INFO:root:[1,  1315] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1316/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.8 ms)
INFO:root:[1,  1316] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1317/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1210.9 ms)
INFO:root:[1,  1317] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1318/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.0 ms)
INFO:root:[1,  1318] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1319/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.1 ms)
INFO:root:[1,  1319] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1320/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.2 ms)
INFO:root:[1,  1320] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1321/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.3 ms)
INFO:root:[1,  1321] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1322/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.4 ms)
INFO:root:[1,  1322] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1323/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.5 ms)
INFO:root:[1,  1323] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1324/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.5 ms)
INFO:root:[1,  1324] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1325/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.6 ms)
INFO:root:[1,  1325] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1326/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.7 ms)
INFO:root:[1,  1326] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1327/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.8 ms)
INFO:root:[1,  1327] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1328/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.9 ms)
INFO:root:[1,  1328] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1329/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1211.9 ms)
INFO:root:[1,  1329] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1330/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.0 ms)
INFO:root:[1,  1330] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1331/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.1 ms)
INFO:root:[1,  1331] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1332/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.2 ms)
INFO:root:[1,  1332] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1333/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.88e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.2 ms)
INFO:root:[1,  1333] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1334/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.3 ms)
INFO:root:[1,  1334] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1335/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.4 ms)
INFO:root:[1,  1335] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1336/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.5 ms)
INFO:root:[1,  1336] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1337/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.5 ms)
INFO:root:[1,  1337] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1338/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.6 ms)
INFO:root:[1,  1338] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1339/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.7 ms)
INFO:root:[1,  1339] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1340/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.7 ms)
INFO:root:[1,  1340] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1341/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.8 ms)
INFO:root:[1,  1341] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1342/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.9 ms)
INFO:root:[1,  1342] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1343/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1212.9 ms)
INFO:root:[1,  1343] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1344/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.0 ms)
INFO:root:[1,  1344] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1345/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.1 ms)
INFO:root:[1,  1345] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1346/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.2 ms)
INFO:root:[1,  1346] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1347/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.3 ms)
INFO:root:[1,  1347] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1348/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.3 ms)
INFO:root:[1,  1348] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1349/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.4 ms)
INFO:root:[1,  1349] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1350/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.5 ms)
INFO:root:[1,  1350] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1351/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.6 ms)
INFO:root:[1,  1351] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1352/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.7 ms)
INFO:root:[1,  1352] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1353/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.7 ms)
INFO:root:[1,  1353] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1354/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.87e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.8 ms)
INFO:root:[1,  1354] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1355/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1213.9 ms)
INFO:root:[1,  1355] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1356/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.0 ms)
INFO:root:[1,  1356] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1357/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.0 ms)
INFO:root:[1,  1357] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1358/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.1 ms)
INFO:root:[1,  1358] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1359/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.2 ms)
INFO:root:[1,  1359] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1360/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.2 ms)
INFO:root:[1,  1360] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1361/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.3 ms)
INFO:root:[1,  1361] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1362/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.4 ms)
INFO:root:[1,  1362] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1363/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.5 ms)
INFO:root:[1,  1363] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1364/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.6 ms)
INFO:root:[1,  1364] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1365/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.7 ms)
INFO:root:[1,  1365] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1366/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.8 ms)
INFO:root:[1,  1366] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1367/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1214.9 ms)
INFO:root:[1,  1367] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1368/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.0 ms)
INFO:root:[1,  1368] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1369/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.1 ms)
INFO:root:[1,  1369] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1370/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.2 ms)
INFO:root:[1,  1370] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1371/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.2 ms)
INFO:root:[1,  1371] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1372/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.3 ms)
INFO:root:[1,  1372] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1373/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.4 ms)
INFO:root:[1,  1373] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1374/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.5 ms)
INFO:root:[1,  1374] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1375/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.6 ms)
INFO:root:[1,  1375] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1376/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.86e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.6 ms)
INFO:root:[1,  1376] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1377/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.7 ms)
INFO:root:[1,  1377] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1378/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.8 ms)
INFO:root:[1,  1378] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1379/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.8 ms)
INFO:root:[1,  1379] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1380/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1215.9 ms)
INFO:root:[1,  1380] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1381/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.0 ms)
INFO:root:[1,  1381] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1382/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.0 ms)
INFO:root:[1,  1382] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1383/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.1 ms)
INFO:root:[1,  1383] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1384/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.2 ms)
INFO:root:[1,  1384] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1385/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.2 ms)
INFO:root:[1,  1385] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1386/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.3 ms)
INFO:root:[1,  1386] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1387/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.4 ms)
INFO:root:[1,  1387] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1388/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.5 ms)
INFO:root:[1,  1388] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1389/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.5 ms)
INFO:root:[1,  1389] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1390/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.6 ms)
INFO:root:[1,  1390] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1391/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.6 ms)
INFO:root:[1,  1391] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1392/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.7 ms)
INFO:root:[1,  1392] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1393/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.8 ms)
INFO:root:[1,  1393] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1394/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.9 ms)
INFO:root:[1,  1394] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1395/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1216.9 ms)
INFO:root:[1,  1395] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1396/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.0 ms)
INFO:root:[1,  1396] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1397/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.85e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.1 ms)
INFO:root:[1,  1397] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1398/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.1 ms)
INFO:root:[1,  1398] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1399/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.2 ms)
INFO:root:[1,  1399] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1400/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.3 ms)
INFO:root:[1,  1400] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1401/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.4 ms)
INFO:root:[1,  1401] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1402/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.4 ms)
INFO:root:[1,  1402] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1403/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.5 ms)
INFO:root:[1,  1403] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1404/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.6 ms)
INFO:root:[1,  1404] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1405/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.7 ms)
INFO:root:[1,  1405] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1406/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.8 ms)
INFO:root:[1,  1406] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1407/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.8 ms)
INFO:root:[1,  1407] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1408/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1217.9 ms)
INFO:root:[1,  1408] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1409/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.0 ms)
INFO:root:[1,  1409] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1410/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.1 ms)
INFO:root:[1,  1410] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1411/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.2 ms)
INFO:root:[1,  1411] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1412/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.3 ms)
INFO:root:[1,  1412] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1413/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.4 ms)
INFO:root:[1,  1413] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1414/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.4 ms)
INFO:root:[1,  1414] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1415/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.5 ms)
INFO:root:[1,  1415] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1416/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.6 ms)
INFO:root:[1,  1416] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1417/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.7 ms)
INFO:root:[1,  1417] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1418/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.84e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.7 ms)
INFO:root:[1,  1418] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1419/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.8 ms)
INFO:root:[1,  1419] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1420/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1218.9 ms)
INFO:root:[1,  1420] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1421/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.0 ms)
INFO:root:[1,  1421] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1422/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.1 ms)
INFO:root:[1,  1422] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1423/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.1 ms)
INFO:root:[1,  1423] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1424/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.2 ms)
INFO:root:[1,  1424] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1425/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.3 ms)
INFO:root:[1,  1425] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1426/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.3 ms)
INFO:root:[1,  1426] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1427/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.4 ms)
INFO:root:[1,  1427] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1428/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.5 ms)
INFO:root:[1,  1428] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1429/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.5 ms)
INFO:root:[1,  1429] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1430/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.6 ms)
INFO:root:[1,  1430] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1431/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.7 ms)
INFO:root:[1,  1431] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1432/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.8 ms)
INFO:root:[1,  1432] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1433/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.8 ms)
INFO:root:[1,  1433] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1434/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1219.9 ms)
INFO:root:[1,  1434] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1435/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.0 ms)
INFO:root:[1,  1435] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1436/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.1 ms)
INFO:root:[1,  1436] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1437/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.2 ms)
INFO:root:[1,  1437] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1438/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.3 ms)
INFO:root:[1,  1438] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1439/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.4 ms)
INFO:root:[1,  1439] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1440/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.83e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.5 ms)
INFO:root:[1,  1440] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1441/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.6 ms)
INFO:root:[1,  1441] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1442/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.7 ms)
INFO:root:[1,  1442] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1443/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.7 ms)
INFO:root:[1,  1443] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1444/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.8 ms)
INFO:root:[1,  1444] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1445/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1220.9 ms)
INFO:root:[1,  1445] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1446/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.0 ms)
INFO:root:[1,  1446] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1447/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.1 ms)
INFO:root:[1,  1447] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1448/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.2 ms)
INFO:root:[1,  1448] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1449/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.3 ms)
INFO:root:[1,  1449] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1450/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.4 ms)
INFO:root:[1,  1450] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1451/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.4 ms)
INFO:root:[1,  1451] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1452/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.5 ms)
INFO:root:[1,  1452] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1453/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.6 ms)
INFO:root:[1,  1453] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1454/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.7 ms)
INFO:root:[1,  1454] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1455/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.8 ms)
INFO:root:[1,  1455] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1456/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.9 ms)
INFO:root:[1,  1456] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1457/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1221.9 ms)
INFO:root:[1,  1457] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1458/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.0 ms)
INFO:root:[1,  1458] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1459/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.1 ms)
INFO:root:[1,  1459] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1460/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.2 ms)
INFO:root:[1,  1460] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1461/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.00e-02] [lr: 7.82e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.2 ms)
INFO:root:[1,  1461] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1462/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.3 ms)
INFO:root:[1,  1462] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1463/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.4 ms)
INFO:root:[1,  1463] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1464/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.5 ms)
INFO:root:[1,  1464] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1465/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.6 ms)
INFO:root:[1,  1465] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1466/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.7 ms)
INFO:root:[1,  1466] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1467/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.8 ms)
INFO:root:[1,  1467] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1468/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.9 ms)
INFO:root:[1,  1468] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1469/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1222.9 ms)
INFO:root:[1,  1469] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1470/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.0 ms)
INFO:root:[1,  1470] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1471/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.0 ms)
INFO:root:[1,  1471] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1472/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.1 ms)
INFO:root:[1,  1472] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1473/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.2 ms)
INFO:root:[1,  1473] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1474/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.3 ms)
INFO:root:[1,  1474] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1475/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.3 ms)
INFO:root:[1,  1475] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1476/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.4 ms)
INFO:root:[1,  1476] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1477/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.5 ms)
INFO:root:[1,  1477] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1478/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.6 ms)
INFO:root:[1,  1478] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1479/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.6 ms)
INFO:root:[1,  1479] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1480/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.7 ms)
INFO:root:[1,  1480] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1481/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.8 ms)
INFO:root:[1,  1481] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1482/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.81e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1223.9 ms)
INFO:root:[1,  1482] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1483/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.0 ms)
INFO:root:[1,  1483] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1484/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.0 ms)
INFO:root:[1,  1484] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1485/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.1 ms)
INFO:root:[1,  1485] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1486/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.2 ms)
INFO:root:[1,  1486] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1487/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.3 ms)
INFO:root:[1,  1487] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1488/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.4 ms)
INFO:root:[1,  1488] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1489/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.5 ms)
INFO:root:[1,  1489] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1490/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.6 ms)
INFO:root:[1,  1490] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1491/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.7 ms)
INFO:root:[1,  1491] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1492/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.8 ms)
INFO:root:[1,  1492] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1493/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1224.9 ms)
INFO:root:[1,  1493] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1494/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.0 ms)
INFO:root:[1,  1494] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1495/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.1 ms)
INFO:root:[1,  1495] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1496/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.2 ms)
INFO:root:[1,  1496] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1497/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.2 ms)
INFO:root:[1,  1497] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1498/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.3 ms)
INFO:root:[1,  1498] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1499/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.4 ms)
INFO:root:[1,  1499] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1500/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.5 ms)
INFO:root:[1,  1500] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1501/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.6 ms)
INFO:root:[1,  1501] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1502/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.7 ms)
INFO:root:[1,  1502] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1503/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.8 ms)
INFO:root:[1,  1503] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1504/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.80e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1225.9 ms)
INFO:root:[1,  1504] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1505/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.0 ms)
INFO:root:[1,  1505] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1506/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.0 ms)
INFO:root:[1,  1506] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1507/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.1 ms)
INFO:root:[1,  1507] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1508/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.2 ms)
INFO:root:[1,  1508] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1509/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.2 ms)
INFO:root:[1,  1509] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1510/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.3 ms)
INFO:root:[1,  1510] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1511/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.5 ms)
INFO:root:[1,  1511] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1512/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.7 ms)
INFO:root:[1,  1512] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1513/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.7 ms)
INFO:root:[1,  1513] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1514/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.8 ms)
INFO:root:[1,  1514] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1515/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1226.9 ms)
INFO:root:[1,  1515] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1516/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.0 ms)
INFO:root:[1,  1516] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1517/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.1 ms)
INFO:root:[1,  1517] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1518/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.2 ms)
INFO:root:[1,  1518] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1519/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.3 ms)
INFO:root:[1,  1519] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1520/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.3 ms)
INFO:root:[1,  1520] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1521/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.4 ms)
INFO:root:[1,  1521] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1522/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.5 ms)
INFO:root:[1,  1522] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1523/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.6 ms)
INFO:root:[1,  1523] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1524/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.6 ms)
INFO:root:[1,  1524] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1525/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.79e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.7 ms)
INFO:root:[1,  1525] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1526/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.8 ms)
INFO:root:[1,  1526] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1527/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.9 ms)
INFO:root:[1,  1527] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1528/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1227.9 ms)
INFO:root:[1,  1528] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1529/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.0 ms)
INFO:root:[1,  1529] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1530/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.1 ms)
INFO:root:[1,  1530] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1531/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.2 ms)
INFO:root:[1,  1531] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1532/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.3 ms)
INFO:root:[1,  1532] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1533/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.4 ms)
INFO:root:[1,  1533] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1534/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.5 ms)
INFO:root:[1,  1534] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1535/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.5 ms)
INFO:root:[1,  1535] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1536/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.6 ms)
INFO:root:[1,  1536] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1537/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.7 ms)
INFO:root:[1,  1537] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1538/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.8 ms)
INFO:root:[1,  1538] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1539/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1228.9 ms)
INFO:root:[1,  1539] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1540/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.0 ms)
INFO:root:[1,  1540] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1541/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.1 ms)
INFO:root:[1,  1541] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1542/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.1 ms)
INFO:root:[1,  1542] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1543/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.2 ms)
INFO:root:[1,  1543] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1544/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.3 ms)
INFO:root:[1,  1544] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1545/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.4 ms)
INFO:root:[1,  1545] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1546/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.78e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.4 ms)
INFO:root:[1,  1546] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1547/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.5 ms)
INFO:root:[1,  1547] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1548/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.6 ms)
INFO:root:[1,  1548] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1549/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.7 ms)
INFO:root:[1,  1549] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1550/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.8 ms)
INFO:root:[1,  1550] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1551/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.8 ms)
INFO:root:[1,  1551] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1552/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1229.9 ms)
INFO:root:[1,  1552] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1553/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.0 ms)
INFO:root:[1,  1553] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1554/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.1 ms)
INFO:root:[1,  1554] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1555/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.2 ms)
INFO:root:[1,  1555] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1556/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.2 ms)
INFO:root:[1,  1556] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1557/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.3 ms)
INFO:root:[1,  1557] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1558/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.4 ms)
INFO:root:[1,  1558] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1559/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.5 ms)
INFO:root:[1,  1559] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1560/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.5 ms)
INFO:root:[1,  1560] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1561/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.6 ms)
INFO:root:[1,  1561] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1562/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.7 ms)
INFO:root:[1,  1562] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1563/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.8 ms)
INFO:root:[1,  1563] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1564/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1230.9 ms)
INFO:root:[1,  1564] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1565/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.0 ms)
INFO:root:[1,  1565] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1566/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.1 ms)
INFO:root:[1,  1566] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1567/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.1 ms)
INFO:root:[1,  1567] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1568/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.77e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.2 ms)
INFO:root:[1,  1568] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1569/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.3 ms)
INFO:root:[1,  1569] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1570/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.4 ms)
INFO:root:[1,  1570] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1571/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.5 ms)
INFO:root:[1,  1571] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1572/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.6 ms)
INFO:root:[1,  1572] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1573/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.7 ms)
INFO:root:[1,  1573] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1574/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.7 ms)
INFO:root:[1,  1574] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1575/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.8 ms)
INFO:root:[1,  1575] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1576/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1231.9 ms)
INFO:root:[1,  1576] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1577/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.0 ms)
INFO:root:[1,  1577] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1578/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.1 ms)
INFO:root:[1,  1578] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1579/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.2 ms)
INFO:root:[1,  1579] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1580/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.3 ms)
INFO:root:[1,  1580] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1581/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.4 ms)
INFO:root:[1,  1581] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1582/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.5 ms)
INFO:root:[1,  1582] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1583/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.6 ms)
INFO:root:[1,  1583] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1584/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.6 ms)
INFO:root:[1,  1584] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1585/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.7 ms)
INFO:root:[1,  1585] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1586/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.8 ms)
INFO:root:[1,  1586] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1587/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1232.9 ms)
INFO:root:[1,  1587] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1588/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.0 ms)
INFO:root:[1,  1588] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1589/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.76e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.0 ms)
INFO:root:[1,  1589] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1590/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.1 ms)
INFO:root:[1,  1590] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1591/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.2 ms)
INFO:root:[1,  1591] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1592/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.3 ms)
INFO:root:[1,  1592] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1593/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.3 ms)
INFO:root:[1,  1593] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1594/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.4 ms)
INFO:root:[1,  1594] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1595/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.5 ms)
INFO:root:[1,  1595] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1596/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.6 ms)
INFO:root:[1,  1596] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1597/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.6 ms)
INFO:root:[1,  1597] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1598/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.7 ms)
INFO:root:[1,  1598] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1599/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.8 ms)
INFO:root:[1,  1599] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1600/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1233.9 ms)
INFO:root:[1,  1600] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1601/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.0 ms)
INFO:root:[1,  1601] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1602/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.1 ms)
INFO:root:[1,  1602] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1603/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.1 ms)
INFO:root:[1,  1603] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1604/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.2 ms)
INFO:root:[1,  1604] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1605/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.3 ms)
INFO:root:[1,  1605] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1606/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.4 ms)
INFO:root:[1,  1606] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1607/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.4 ms)
INFO:root:[1,  1607] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1608/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.5 ms)
INFO:root:[1,  1608] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1609/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.6 ms)
INFO:root:[1,  1609] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1610/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.75e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.7 ms)
INFO:root:[1,  1610] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1611/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.7 ms)
INFO:root:[1,  1611] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1612/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.8 ms)
INFO:root:[1,  1612] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1613/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1234.9 ms)
INFO:root:[1,  1613] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1614/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.0 ms)
INFO:root:[1,  1614] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1615/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.1 ms)
INFO:root:[1,  1615] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1616/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.2 ms)
INFO:root:[1,  1616] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1617/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.3 ms)
INFO:root:[1,  1617] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1618/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.4 ms)
INFO:root:[1,  1618] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1619/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.5 ms)
INFO:root:[1,  1619] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1620/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.6 ms)
INFO:root:[1,  1620] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1621/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.7 ms)
INFO:root:[1,  1621] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1622/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.8 ms)
INFO:root:[1,  1622] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1623/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.8 ms)
INFO:root:[1,  1623] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1624/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1235.9 ms)
INFO:root:[1,  1624] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1625/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.0 ms)
INFO:root:[1,  1625] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1626/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.1 ms)
INFO:root:[1,  1626] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1627/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.1 ms)
INFO:root:[1,  1627] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1628/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.2 ms)
INFO:root:[1,  1628] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1629/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.3 ms)
INFO:root:[1,  1629] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1630/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.4 ms)
INFO:root:[1,  1630] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1631/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.5 ms)
INFO:root:[1,  1631] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1632/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.74e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.5 ms)
INFO:root:[1,  1632] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1633/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.6 ms)
INFO:root:[1,  1633] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1634/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.7 ms)
INFO:root:[1,  1634] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1635/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.8 ms)
INFO:root:[1,  1635] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1636/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.8 ms)
INFO:root:[1,  1636] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1637/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1236.9 ms)
INFO:root:[1,  1637] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1638/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.0 ms)
INFO:root:[1,  1638] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1639/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.0 ms)
INFO:root:[1,  1639] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1640/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.1 ms)
INFO:root:[1,  1640] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1641/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.2 ms)
INFO:root:[1,  1641] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1642/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.2 ms)
INFO:root:[1,  1642] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1643/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.3 ms)
INFO:root:[1,  1643] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1644/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.4 ms)
INFO:root:[1,  1644] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1645/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.5 ms)
INFO:root:[1,  1645] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1646/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.5 ms)
INFO:root:[1,  1646] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1647/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.6 ms)
INFO:root:[1,  1647] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1648/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.7 ms)
INFO:root:[1,  1648] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1649/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.8 ms)
INFO:root:[1,  1649] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1650/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1237.9 ms)
INFO:root:[1,  1650] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1651/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.0 ms)
INFO:root:[1,  1651] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1652/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.1 ms)
INFO:root:[1,  1652] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1653/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.73e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.1 ms)
INFO:root:[1,  1653] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1654/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.2 ms)
INFO:root:[1,  1654] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1655/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.3 ms)
INFO:root:[1,  1655] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1656/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.4 ms)
INFO:root:[1,  1656] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1657/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.5 ms)
INFO:root:[1,  1657] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1658/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.6 ms)
INFO:root:[1,  1658] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1659/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.7 ms)
INFO:root:[1,  1659] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1660/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.8 ms)
INFO:root:[1,  1660] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1661/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.9 ms)
INFO:root:[1,  1661] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1662/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1238.9 ms)
INFO:root:[1,  1662] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1663/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.0 ms)
INFO:root:[1,  1663] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1664/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.1 ms)
INFO:root:[1,  1664] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1665/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.2 ms)
INFO:root:[1,  1665] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1666/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.3 ms)
INFO:root:[1,  1666] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1667/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.3 ms)
INFO:root:[1,  1667] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1668/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.4 ms)
INFO:root:[1,  1668] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1669/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.5 ms)
INFO:root:[1,  1669] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1670/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.6 ms)
INFO:root:[1,  1670] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1671/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.7 ms)
INFO:root:[1,  1671] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1672/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.7 ms)
INFO:root:[1,  1672] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1673/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.8 ms)
INFO:root:[1,  1673] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1674/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.72e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1239.8 ms)
INFO:root:[1,  1674] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1675/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.0 ms)
INFO:root:[1,  1675] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1676/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.0 ms)
INFO:root:[1,  1676] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1677/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.1 ms)
INFO:root:[1,  1677] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1678/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.2 ms)
INFO:root:[1,  1678] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1679/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.3 ms)
INFO:root:[1,  1679] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1680/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.4 ms)
INFO:root:[1,  1680] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1681/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.5 ms)
INFO:root:[1,  1681] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1682/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.5 ms)
INFO:root:[1,  1682] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1683/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.6 ms)
INFO:root:[1,  1683] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1684/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.7 ms)
INFO:root:[1,  1684] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1685/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.8 ms)
INFO:root:[1,  1685] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1686/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.8 ms)
INFO:root:[1,  1686] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1687/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1240.9 ms)
INFO:root:[1,  1687] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1688/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.0 ms)
INFO:root:[1,  1688] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1689/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.1 ms)
INFO:root:[1,  1689] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1690/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.2 ms)
INFO:root:[1,  1690] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1691/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.3 ms)
INFO:root:[1,  1691] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1692/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.3 ms)
INFO:root:[1,  1692] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1693/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.4 ms)
INFO:root:[1,  1693] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1694/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.5 ms)
INFO:root:[1,  1694] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1695/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.6 ms)
INFO:root:[1,  1695] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1696/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.71e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.7 ms)
INFO:root:[1,  1696] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1697/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.7 ms)
INFO:root:[1,  1697] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1698/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.8 ms)
INFO:root:[1,  1698] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1699/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1241.9 ms)
INFO:root:[1,  1699] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1700/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.0 ms)
INFO:root:[1,  1700] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1701/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.1 ms)
INFO:root:[1,  1701] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1702/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.2 ms)
INFO:root:[1,  1702] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1703/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.3 ms)
INFO:root:[1,  1703] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1704/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.4 ms)
INFO:root:[1,  1704] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1705/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.5 ms)
INFO:root:[1,  1705] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1706/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.6 ms)
INFO:root:[1,  1706] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1707/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.6 ms)
INFO:root:[1,  1707] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1708/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.7 ms)
INFO:root:[1,  1708] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1709/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.8 ms)
INFO:root:[1,  1709] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1710/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1242.9 ms)
INFO:root:[1,  1710] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1711/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.0 ms)
INFO:root:[1,  1711] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1712/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.1 ms)
INFO:root:[1,  1712] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1713/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.1 ms)
INFO:root:[1,  1713] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1714/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.2 ms)
INFO:root:[1,  1714] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1715/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.3 ms)
INFO:root:[1,  1715] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1716/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.4 ms)
INFO:root:[1,  1716] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1717/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.70e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.4 ms)
INFO:root:[1,  1717] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1718/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.5 ms)
INFO:root:[1,  1718] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1719/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.6 ms)
INFO:root:[1,  1719] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1720/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.7 ms)
INFO:root:[1,  1720] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1721/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.8 ms)
INFO:root:[1,  1721] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1722/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.8 ms)
INFO:root:[1,  1722] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1723/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1243.9 ms)
INFO:root:[1,  1723] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1724/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.0 ms)
INFO:root:[1,  1724] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1725/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.1 ms)
INFO:root:[1,  1725] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1726/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.1 ms)
INFO:root:[1,  1726] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1727/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.2 ms)
INFO:root:[1,  1727] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1728/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.3 ms)
INFO:root:[1,  1728] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1729/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.4 ms)
INFO:root:[1,  1729] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1730/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.5 ms)
INFO:root:[1,  1730] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1731/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.6 ms)
INFO:root:[1,  1731] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1732/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.7 ms)
INFO:root:[1,  1732] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1733/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.7 ms)
INFO:root:[1,  1733] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1734/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.8 ms)
INFO:root:[1,  1734] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1735/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1244.9 ms)
INFO:root:[1,  1735] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1736/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.0 ms)
INFO:root:[1,  1736] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1737/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.0 ms)
INFO:root:[1,  1737] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1738/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.1 ms)
INFO:root:[1,  1738] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1739/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.69e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.2 ms)
INFO:root:[1,  1739] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1740/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.3 ms)
INFO:root:[1,  1740] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1741/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.4 ms)
INFO:root:[1,  1741] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1742/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.5 ms)
INFO:root:[1,  1742] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1743/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.6 ms)
INFO:root:[1,  1743] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1744/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.7 ms)
INFO:root:[1,  1744] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1745/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.7 ms)
INFO:root:[1,  1745] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1746/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1245.9 ms)
INFO:root:[1,  1746] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1747/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.0 ms)
INFO:root:[1,  1747] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1748/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.1 ms)
INFO:root:[1,  1748] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1749/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.1 ms)
INFO:root:[1,  1749] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1750/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.2 ms)
INFO:root:[1,  1750] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1751/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.3 ms)
INFO:root:[1,  1751] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1752/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.4 ms)
INFO:root:[1,  1752] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1753/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.5 ms)
INFO:root:[1,  1753] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1754/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.5 ms)
INFO:root:[1,  1754] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1755/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.6 ms)
INFO:root:[1,  1755] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1756/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.7 ms)
INFO:root:[1,  1756] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1757/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.7 ms)
INFO:root:[1,  1757] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1758/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.8 ms)
INFO:root:[1,  1758] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1759/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1246.9 ms)
INFO:root:[1,  1759] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1760/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.68e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.0 ms)
INFO:root:[1,  1760] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1761/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.0 ms)
INFO:root:[1,  1761] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1762/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.1 ms)
INFO:root:[1,  1762] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1763/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.2 ms)
INFO:root:[1,  1763] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1764/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.3 ms)
INFO:root:[1,  1764] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1765/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.4 ms)
INFO:root:[1,  1765] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1766/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.4 ms)
INFO:root:[1,  1766] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1767/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.5 ms)
INFO:root:[1,  1767] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1768/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.6 ms)
INFO:root:[1,  1768] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1769/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.7 ms)
INFO:root:[1,  1769] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1770/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.8 ms)
INFO:root:[1,  1770] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1771/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.9 ms)
INFO:root:[1,  1771] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1772/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1247.9 ms)
INFO:root:[1,  1772] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1773/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.0 ms)
INFO:root:[1,  1773] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1774/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.1 ms)
INFO:root:[1,  1774] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1775/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.2 ms)
INFO:root:[1,  1775] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1776/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.3 ms)
INFO:root:[1,  1776] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1777/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.3 ms)
INFO:root:[1,  1777] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1778/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.4 ms)
INFO:root:[1,  1778] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1779/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.5 ms)
INFO:root:[1,  1779] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1780/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.6 ms)
INFO:root:[1,  1780] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1781/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.67e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.7 ms)
INFO:root:[1,  1781] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1782/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.8 ms)
INFO:root:[1,  1782] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1783/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1248.9 ms)
INFO:root:[1,  1783] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1784/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.0 ms)
INFO:root:[1,  1784] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1785/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.1 ms)
INFO:root:[1,  1785] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1786/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.1 ms)
INFO:root:[1,  1786] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1787/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.2 ms)
INFO:root:[1,  1787] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1788/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.3 ms)
INFO:root:[1,  1788] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1789/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.4 ms)
INFO:root:[1,  1789] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1790/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.5 ms)
INFO:root:[1,  1790] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1791/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.6 ms)
INFO:root:[1,  1791] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1792/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.7 ms)
INFO:root:[1,  1792] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1793/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.8 ms)
INFO:root:[1,  1793] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1794/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.8 ms)
INFO:root:[1,  1794] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1795/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1249.9 ms)
INFO:root:[1,  1795] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1796/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.0 ms)
INFO:root:[1,  1796] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1797/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.0 ms)
INFO:root:[1,  1797] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1798/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.1 ms)
INFO:root:[1,  1798] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1799/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.2 ms)
INFO:root:[1,  1799] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1800/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.3 ms)
INFO:root:[1,  1800] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1801/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.3 ms)
INFO:root:[1,  1801] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1802/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.4 ms)
INFO:root:[1,  1802] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1803/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.66e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.5 ms)
INFO:root:[1,  1803] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1804/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.6 ms)
INFO:root:[1,  1804] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1805/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.7 ms)
INFO:root:[1,  1805] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1806/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.8 ms)
INFO:root:[1,  1806] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1807/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.8 ms)
INFO:root:[1,  1807] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1808/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1250.9 ms)
INFO:root:[1,  1808] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1809/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.0 ms)
INFO:root:[1,  1809] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1810/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.0 ms)
INFO:root:[1,  1810] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1811/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.1 ms)
INFO:root:[1,  1811] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1812/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.2 ms)
INFO:root:[1,  1812] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1813/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.2 ms)
INFO:root:[1,  1813] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1814/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.3 ms)
INFO:root:[1,  1814] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1815/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.4 ms)
INFO:root:[1,  1815] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1816/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.5 ms)
INFO:root:[1,  1816] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1817/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.6 ms)
INFO:root:[1,  1817] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1818/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.6 ms)
INFO:root:[1,  1818] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1819/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.7 ms)
INFO:root:[1,  1819] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1820/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.8 ms)
INFO:root:[1,  1820] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1821/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1251.9 ms)
INFO:root:[1,  1821] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1822/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.0 ms)
INFO:root:[1,  1822] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1823/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.1 ms)
INFO:root:[1,  1823] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1824/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.65e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.2 ms)
INFO:root:[1,  1824] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1825/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.2 ms)
INFO:root:[1,  1825] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1826/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.3 ms)
INFO:root:[1,  1826] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1827/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.4 ms)
INFO:root:[1,  1827] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1828/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.5 ms)
INFO:root:[1,  1828] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1829/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.6 ms)
INFO:root:[1,  1829] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1830/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.7 ms)
INFO:root:[1,  1830] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1831/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.8 ms)
INFO:root:[1,  1831] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1832/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1252.9 ms)
INFO:root:[1,  1832] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1833/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.0 ms)
INFO:root:[1,  1833] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1834/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.1 ms)
INFO:root:[1,  1834] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1835/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.2 ms)
INFO:root:[1,  1835] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1836/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.2 ms)
INFO:root:[1,  1836] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1837/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.3 ms)
INFO:root:[1,  1837] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1838/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.4 ms)
INFO:root:[1,  1838] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1839/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.4 ms)
INFO:root:[1,  1839] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1840/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.5 ms)
INFO:root:[1,  1840] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1841/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.6 ms)
INFO:root:[1,  1841] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1842/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.7 ms)
INFO:root:[1,  1842] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1843/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.8 ms)
INFO:root:[1,  1843] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1844/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.8 ms)
INFO:root:[1,  1844] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1845/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.64e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1253.9 ms)
INFO:root:[1,  1845] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1846/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.0 ms)
INFO:root:[1,  1846] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1847/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.0 ms)
INFO:root:[1,  1847] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1848/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.1 ms)
INFO:root:[1,  1848] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1849/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.2 ms)
INFO:root:[1,  1849] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1850/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.3 ms)
INFO:root:[1,  1850] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1851/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.4 ms)
INFO:root:[1,  1851] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1852/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.5 ms)
INFO:root:[1,  1852] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1853/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.5 ms)
INFO:root:[1,  1853] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1854/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.6 ms)
INFO:root:[1,  1854] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1855/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.7 ms)
INFO:root:[1,  1855] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1856/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.8 ms)
INFO:root:[1,  1856] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1857/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1254.9 ms)
INFO:root:[1,  1857] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1858/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.0 ms)
INFO:root:[1,  1858] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1859/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.1 ms)
INFO:root:[1,  1859] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1860/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.2 ms)
INFO:root:[1,  1860] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1861/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.3 ms)
INFO:root:[1,  1861] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1862/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.4 ms)
INFO:root:[1,  1862] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1863/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.5 ms)
INFO:root:[1,  1863] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1864/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.5 ms)
INFO:root:[1,  1864] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1865/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.6 ms)
INFO:root:[1,  1865] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1866/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.7 ms)
INFO:root:[1,  1866] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1867/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.63e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.8 ms)
INFO:root:[1,  1867] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1868/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.9 ms)
INFO:root:[1,  1868] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1869/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1255.9 ms)
INFO:root:[1,  1869] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1870/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.0 ms)
INFO:root:[1,  1870] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1871/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.1 ms)
INFO:root:[1,  1871] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1872/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.2 ms)
INFO:root:[1,  1872] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1873/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.3 ms)
INFO:root:[1,  1873] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1874/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.4 ms)
INFO:root:[1,  1874] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1875/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.4 ms)
INFO:root:[1,  1875] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1876/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.5 ms)
INFO:root:[1,  1876] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1877/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.7 ms)
INFO:root:[1,  1877] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1878/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.7 ms)
INFO:root:[1,  1878] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1879/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1256.8 ms)
INFO:root:[1,  1879] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1880/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.0 ms)
INFO:root:[1,  1880] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1881/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.0 ms)
INFO:root:[1,  1881] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1882/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.1 ms)
INFO:root:[1,  1882] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1883/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.2 ms)
INFO:root:[1,  1883] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1884/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.3 ms)
INFO:root:[1,  1884] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1885/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.3 ms)
INFO:root:[1,  1885] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1886/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.4 ms)
INFO:root:[1,  1886] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1887/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.5 ms)
INFO:root:[1,  1887] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1888/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.62e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.6 ms)
INFO:root:[1,  1888] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1889/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.7 ms)
INFO:root:[1,  1889] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1890/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.8 ms)
INFO:root:[1,  1890] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1891/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.8 ms)
INFO:root:[1,  1891] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1892/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1257.9 ms)
INFO:root:[1,  1892] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1893/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.0 ms)
INFO:root:[1,  1893] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1894/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.0 ms)
INFO:root:[1,  1894] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1895/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.1 ms)
INFO:root:[1,  1895] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1896/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.2 ms)
INFO:root:[1,  1896] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1897/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.3 ms)
INFO:root:[1,  1897] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1898/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.4 ms)
INFO:root:[1,  1898] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1899/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.5 ms)
INFO:root:[1,  1899] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1900/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.6 ms)
INFO:root:[1,  1900] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1901/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.6 ms)
INFO:root:[1,  1901] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1902/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.7 ms)
INFO:root:[1,  1902] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1903/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.8 ms)
INFO:root:[1,  1903] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1904/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.9 ms)
INFO:root:[1,  1904] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1905/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1258.9 ms)
INFO:root:[1,  1905] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1906/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.0 ms)
INFO:root:[1,  1906] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1907/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.1 ms)
INFO:root:[1,  1907] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1908/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.2 ms)
INFO:root:[1,  1908] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1909/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.61e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.3 ms)
INFO:root:[1,  1909] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1910/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.4 ms)
INFO:root:[1,  1910] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1911/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.5 ms)
INFO:root:[1,  1911] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1912/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.6 ms)
INFO:root:[1,  1912] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1913/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.8 ms)
INFO:root:[1,  1913] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1914/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.9 ms)
INFO:root:[1,  1914] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1915/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1259.9 ms)
INFO:root:[1,  1915] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1916/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.0 ms)
INFO:root:[1,  1916] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1917/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.1 ms)
INFO:root:[1,  1917] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1918/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.2 ms)
INFO:root:[1,  1918] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1919/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.3 ms)
INFO:root:[1,  1919] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1920/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.3 ms)
INFO:root:[1,  1920] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1921/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.4 ms)
INFO:root:[1,  1921] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1922/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.5 ms)
INFO:root:[1,  1922] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1923/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.5 ms)
INFO:root:[1,  1923] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1924/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.6 ms)
INFO:root:[1,  1924] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1925/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.7 ms)
INFO:root:[1,  1925] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1926/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.8 ms)
INFO:root:[1,  1926] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1927/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1260.9 ms)
INFO:root:[1,  1927] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1928/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.0 ms)
INFO:root:[1,  1928] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1929/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.1 ms)
INFO:root:[1,  1929] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1930/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.1 ms)
INFO:root:[1,  1930] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1931/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.60e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.2 ms)
INFO:root:[1,  1931] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1932/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.3 ms)
INFO:root:[1,  1932] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1933/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.4 ms)
INFO:root:[1,  1933] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1934/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.4 ms)
INFO:root:[1,  1934] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1935/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.5 ms)
INFO:root:[1,  1935] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1936/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.6 ms)
INFO:root:[1,  1936] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1937/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.7 ms)
INFO:root:[1,  1937] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1938/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.8 ms)
INFO:root:[1,  1938] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1939/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1261.9 ms)
INFO:root:[1,  1939] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1940/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.0 ms)
INFO:root:[1,  1940] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1941/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.0 ms)
INFO:root:[1,  1941] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1942/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.1 ms)
INFO:root:[1,  1942] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1943/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.2 ms)
INFO:root:[1,  1943] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1944/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.3 ms)
INFO:root:[1,  1944] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1945/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.3 ms)
INFO:root:[1,  1945] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1946/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.4 ms)
INFO:root:[1,  1946] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1947/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.5 ms)
INFO:root:[1,  1947] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1948/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.58e-04][mem: 6.87e+04] (1262.6 ms)
INFO:root:[1,  1948] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1949/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1262.7 ms)
INFO:root:[1,  1949] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1950/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1262.8 ms)
INFO:root:[1,  1950] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1951/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1262.9 ms)
INFO:root:[1,  1951] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1952/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.59e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.0 ms)
INFO:root:[1,  1952] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1953/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.1 ms)
INFO:root:[1,  1953] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1954/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.2 ms)
INFO:root:[1,  1954] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1955/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.3 ms)
INFO:root:[1,  1955] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1956/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.3 ms)
INFO:root:[1,  1956] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1957/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.4 ms)
INFO:root:[1,  1957] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1958/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.5 ms)
INFO:root:[1,  1958] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1959/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.6 ms)
INFO:root:[1,  1959] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1960/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.7 ms)
INFO:root:[1,  1960] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1961/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.8 ms)
INFO:root:[1,  1961] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1962/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1263.9 ms)
INFO:root:[1,  1962] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1963/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.0 ms)
INFO:root:[1,  1963] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1964/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.0 ms)
INFO:root:[1,  1964] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1965/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.1 ms)
INFO:root:[1,  1965] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1966/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.2 ms)
INFO:root:[1,  1966] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1967/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.3 ms)
INFO:root:[1,  1967] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1968/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.4 ms)
INFO:root:[1,  1968] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1969/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.5 ms)
INFO:root:[1,  1969] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1970/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.6 ms)
INFO:root:[1,  1970] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1971/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.7 ms)
INFO:root:[1,  1971] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1972/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.8 ms)
INFO:root:[1,  1972] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1973/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.58e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.9 ms)
INFO:root:[1,  1973] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1974/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1264.9 ms)
INFO:root:[1,  1974] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1975/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.0 ms)
INFO:root:[1,  1975] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1976/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.1 ms)
INFO:root:[1,  1976] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1977/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.2 ms)
INFO:root:[1,  1977] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1978/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.2 ms)
INFO:root:[1,  1978] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1979/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.3 ms)
INFO:root:[1,  1979] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1980/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.4 ms)
INFO:root:[1,  1980] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1981/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.5 ms)
INFO:root:[1,  1981] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1982/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.6 ms)
INFO:root:[1,  1982] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1983/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.7 ms)
INFO:root:[1,  1983] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1984/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.7 ms)
INFO:root:[1,  1984] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1985/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.8 ms)
INFO:root:[1,  1985] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1986/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1265.9 ms)
INFO:root:[1,  1986] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1987/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.0 ms)
INFO:root:[1,  1987] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1988/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.0 ms)
INFO:root:[1,  1988] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1989/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.1 ms)
INFO:root:[1,  1989] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1990/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.2 ms)
INFO:root:[1,  1990] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1991/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.3 ms)
INFO:root:[1,  1991] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1992/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.4 ms)
INFO:root:[1,  1992] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1993/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.5 ms)
INFO:root:[1,  1993] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1994/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.6 ms)
INFO:root:[1,  1994] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1995/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.57e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.6 ms)
INFO:root:[1,  1995] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1996/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.7 ms)
INFO:root:[1,  1996] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1997/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.8 ms)
INFO:root:[1,  1997] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1998/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1266.9 ms)
INFO:root:[1,  1998] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  1999/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.0 ms)
INFO:root:[1,  1999] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2000/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.1 ms)
INFO:root:[1,  2000] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2001/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.2 ms)
INFO:root:[1,  2001] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2002/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.2 ms)
INFO:root:[1,  2002] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2003/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.3 ms)
INFO:root:[1,  2003] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2004/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.4 ms)
INFO:root:[1,  2004] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2005/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.5 ms)
INFO:root:[1,  2005] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2006/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.6 ms)
INFO:root:[1,  2006] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2007/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.7 ms)
INFO:root:[1,  2007] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2008/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.7 ms)
INFO:root:[1,  2008] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2009/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.8 ms)
INFO:root:[1,  2009] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2010/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.9 ms)
INFO:root:[1,  2010] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2011/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1267.9 ms)
INFO:root:[1,  2011] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2012/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.0 ms)
INFO:root:[1,  2012] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2013/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.1 ms)
INFO:root:[1,  2013] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2014/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.2 ms)
INFO:root:[1,  2014] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2015/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.3 ms)
INFO:root:[1,  2015] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2016/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.56e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.3 ms)
INFO:root:[1,  2016] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2017/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.4 ms)
INFO:root:[1,  2017] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2018/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.5 ms)
INFO:root:[1,  2018] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2019/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.6 ms)
INFO:root:[1,  2019] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2020/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.7 ms)
INFO:root:[1,  2020] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2021/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.7 ms)
INFO:root:[1,  2021] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2022/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1268.8 ms)
INFO:root:[1,  2022] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2023/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.0 ms)
INFO:root:[1,  2023] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2024/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.1 ms)
INFO:root:[1,  2024] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2025/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.1 ms)
INFO:root:[1,  2025] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2026/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.2 ms)
INFO:root:[1,  2026] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2027/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.3 ms)
INFO:root:[1,  2027] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2028/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.4 ms)
INFO:root:[1,  2028] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2029/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.5 ms)
INFO:root:[1,  2029] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2030/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.6 ms)
INFO:root:[1,  2030] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2031/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.7 ms)
INFO:root:[1,  2031] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2032/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.8 ms)
INFO:root:[1,  2032] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2033/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1269.9 ms)
INFO:root:[1,  2033] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2034/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.0 ms)
INFO:root:[1,  2034] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2035/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.1 ms)
INFO:root:[1,  2035] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2036/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.2 ms)
INFO:root:[1,  2036] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2037/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.55e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.3 ms)
INFO:root:[1,  2037] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2038/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.4 ms)
INFO:root:[1,  2038] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2039/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.4 ms)
INFO:root:[1,  2039] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2040/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.5 ms)
INFO:root:[1,  2040] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2041/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.6 ms)
INFO:root:[1,  2041] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2042/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.7 ms)
INFO:root:[1,  2042] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2043/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.8 ms)
INFO:root:[1,  2043] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2044/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.8 ms)
INFO:root:[1,  2044] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2045/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1270.9 ms)
INFO:root:[1,  2045] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2046/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.0 ms)
INFO:root:[1,  2046] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2047/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.1 ms)
INFO:root:[1,  2047] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2048/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.2 ms)
INFO:root:[1,  2048] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2049/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.3 ms)
INFO:root:[1,  2049] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2050/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.4 ms)
INFO:root:[1,  2050] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2051/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.4 ms)
INFO:root:[1,  2051] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2052/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.5 ms)
INFO:root:[1,  2052] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2053/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.6 ms)
INFO:root:[1,  2053] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2054/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.7 ms)
INFO:root:[1,  2054] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2055/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.8 ms)
INFO:root:[1,  2055] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2056/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1271.9 ms)
INFO:root:[1,  2056] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2057/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.1 ms)
INFO:root:[1,  2057] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2058/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.1 ms)
INFO:root:[1,  2058] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2059/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.54e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.2 ms)
INFO:root:[1,  2059] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2060/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.3 ms)
INFO:root:[1,  2060] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2061/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.4 ms)
INFO:root:[1,  2061] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2062/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.4 ms)
INFO:root:[1,  2062] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2063/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.5 ms)
INFO:root:[1,  2063] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2064/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.6 ms)
INFO:root:[1,  2064] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2065/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.7 ms)
INFO:root:[1,  2065] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2066/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.8 ms)
INFO:root:[1,  2066] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2067/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1272.9 ms)
INFO:root:[1,  2067] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2068/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.0 ms)
INFO:root:[1,  2068] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2069/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.1 ms)
INFO:root:[1,  2069] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2070/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.2 ms)
INFO:root:[1,  2070] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2071/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.3 ms)
INFO:root:[1,  2071] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2072/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.4 ms)
INFO:root:[1,  2072] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2073/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.5 ms)
INFO:root:[1,  2073] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2074/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.6 ms)
INFO:root:[1,  2074] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2075/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.7 ms)
INFO:root:[1,  2075] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2076/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.8 ms)
INFO:root:[1,  2076] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2077/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1273.9 ms)
INFO:root:[1,  2077] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2078/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.0 ms)
INFO:root:[1,  2078] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2079/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.1 ms)
INFO:root:[1,  2079] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2080/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.53e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.2 ms)
INFO:root:[1,  2080] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2081/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.3 ms)
INFO:root:[1,  2081] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2082/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.3 ms)
INFO:root:[1,  2082] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2083/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.4 ms)
INFO:root:[1,  2083] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2084/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.5 ms)
INFO:root:[1,  2084] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2085/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.6 ms)
INFO:root:[1,  2085] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2086/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.7 ms)
INFO:root:[1,  2086] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2087/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.8 ms)
INFO:root:[1,  2087] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2088/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.9 ms)
INFO:root:[1,  2088] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2089/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1274.9 ms)
INFO:root:[1,  2089] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2090/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.0 ms)
INFO:root:[1,  2090] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2091/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.1 ms)
INFO:root:[1,  2091] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2092/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.2 ms)
INFO:root:[1,  2092] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2093/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.3 ms)
INFO:root:[1,  2093] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2094/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.4 ms)
INFO:root:[1,  2094] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2095/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.5 ms)
INFO:root:[1,  2095] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2096/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.5 ms)
INFO:root:[1,  2096] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2097/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.6 ms)
INFO:root:[1,  2097] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2098/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.7 ms)
INFO:root:[1,  2098] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2099/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.7 ms)
INFO:root:[1,  2099] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2100/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.8 ms)
INFO:root:[1,  2100] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2101/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.52e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1275.9 ms)
INFO:root:[1,  2101] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2102/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.0 ms)
INFO:root:[1,  2102] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2103/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.1 ms)
INFO:root:[1,  2103] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2104/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.2 ms)
INFO:root:[1,  2104] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2105/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.2 ms)
INFO:root:[1,  2105] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2106/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.3 ms)
INFO:root:[1,  2106] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2107/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.4 ms)
INFO:root:[1,  2107] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2108/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.4 ms)
INFO:root:[1,  2108] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2109/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.5 ms)
INFO:root:[1,  2109] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2110/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.6 ms)
INFO:root:[1,  2110] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2111/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.7 ms)
INFO:root:[1,  2111] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2112/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.8 ms)
INFO:root:[1,  2112] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2113/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1276.9 ms)
INFO:root:[1,  2113] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2114/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.0 ms)
INFO:root:[1,  2114] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2115/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.1 ms)
INFO:root:[1,  2115] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2116/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.2 ms)
INFO:root:[1,  2116] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2117/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.3 ms)
INFO:root:[1,  2117] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2118/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.3 ms)
INFO:root:[1,  2118] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2119/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.4 ms)
INFO:root:[1,  2119] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2120/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.5 ms)
INFO:root:[1,  2120] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2121/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.6 ms)
INFO:root:[1,  2121] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2122/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.7 ms)
INFO:root:[1,  2122] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2123/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.51e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.8 ms)
INFO:root:[1,  2123] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2124/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1277.9 ms)
INFO:root:[1,  2124] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2125/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.0 ms)
INFO:root:[1,  2125] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2126/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.0 ms)
INFO:root:[1,  2126] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2127/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.1 ms)
INFO:root:[1,  2127] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2128/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.2 ms)
INFO:root:[1,  2128] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2129/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.3 ms)
INFO:root:[1,  2129] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2130/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.4 ms)
INFO:root:[1,  2130] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2131/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.5 ms)
INFO:root:[1,  2131] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2132/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.6 ms)
INFO:root:[1,  2132] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2133/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.7 ms)
INFO:root:[1,  2133] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2134/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.7 ms)
INFO:root:[1,  2134] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2135/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.8 ms)
INFO:root:[1,  2135] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2136/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1278.9 ms)
INFO:root:[1,  2136] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2137/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.0 ms)
INFO:root:[1,  2137] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2138/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.1 ms)
INFO:root:[1,  2138] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2139/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.2 ms)
INFO:root:[1,  2139] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2140/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.3 ms)
INFO:root:[1,  2140] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2141/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.4 ms)
INFO:root:[1,  2141] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2142/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.5 ms)
INFO:root:[1,  2142] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2143/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.5 ms)
INFO:root:[1,  2143] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2144/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.50e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.6 ms)
INFO:root:[1,  2144] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2145/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.7 ms)
INFO:root:[1,  2145] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2146/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.8 ms)
INFO:root:[1,  2146] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2147/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.9 ms)
INFO:root:[1,  2147] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2148/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1279.9 ms)
INFO:root:[1,  2148] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2149/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.0 ms)
INFO:root:[1,  2149] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2150/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.1 ms)
INFO:root:[1,  2150] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2151/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.1 ms)
INFO:root:[1,  2151] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2152/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.2 ms)
INFO:root:[1,  2152] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2153/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.3 ms)
INFO:root:[1,  2153] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2154/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.4 ms)
INFO:root:[1,  2154] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2155/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.5 ms)
INFO:root:[1,  2155] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2156/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.6 ms)
INFO:root:[1,  2156] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2157/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.7 ms)
INFO:root:[1,  2157] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2158/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.8 ms)
INFO:root:[1,  2158] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2159/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1280.9 ms)
INFO:root:[1,  2159] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2160/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.0 ms)
INFO:root:[1,  2160] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2161/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.1 ms)
INFO:root:[1,  2161] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2162/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.2 ms)
INFO:root:[1,  2162] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2163/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.3 ms)
INFO:root:[1,  2163] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2164/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.4 ms)
INFO:root:[1,  2164] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2165/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.4 ms)
INFO:root:[1,  2165] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2166/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.49e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.5 ms)
INFO:root:[1,  2166] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2167/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.6 ms)
INFO:root:[1,  2167] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2168/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.7 ms)
INFO:root:[1,  2168] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2169/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.8 ms)
INFO:root:[1,  2169] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2170/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1281.9 ms)
INFO:root:[1,  2170] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2171/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.0 ms)
INFO:root:[1,  2171] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2172/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.1 ms)
INFO:root:[1,  2172] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2173/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.2 ms)
INFO:root:[1,  2173] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2174/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.2 ms)
INFO:root:[1,  2174] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2175/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.3 ms)
INFO:root:[1,  2175] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2176/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.4 ms)
INFO:root:[1,  2176] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2177/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.5 ms)
INFO:root:[1,  2177] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2178/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.6 ms)
INFO:root:[1,  2178] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2179/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.6 ms)
INFO:root:[1,  2179] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2180/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.7 ms)
INFO:root:[1,  2180] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2181/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.8 ms)
INFO:root:[1,  2181] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2182/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1282.9 ms)
INFO:root:[1,  2182] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2183/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.0 ms)
INFO:root:[1,  2183] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2184/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.1 ms)
INFO:root:[1,  2184] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2185/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.1 ms)
INFO:root:[1,  2185] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2186/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.3 ms)
INFO:root:[1,  2186] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2187/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.48e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.3 ms)
INFO:root:[1,  2187] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2188/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.4 ms)
INFO:root:[1,  2188] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2189/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.5 ms)
INFO:root:[1,  2189] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2190/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.6 ms)
INFO:root:[1,  2190] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2191/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.7 ms)
INFO:root:[1,  2191] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2192/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.8 ms)
INFO:root:[1,  2192] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2193/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1283.9 ms)
INFO:root:[1,  2193] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2194/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.0 ms)
INFO:root:[1,  2194] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2195/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.1 ms)
INFO:root:[1,  2195] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2196/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.1 ms)
INFO:root:[1,  2196] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2197/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.2 ms)
INFO:root:[1,  2197] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2198/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.3 ms)
INFO:root:[1,  2198] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2199/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.4 ms)
INFO:root:[1,  2199] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2200/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.5 ms)
INFO:root:[1,  2200] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2201/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.6 ms)
INFO:root:[1,  2201] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2202/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.7 ms)
INFO:root:[1,  2202] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2203/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.8 ms)
INFO:root:[1,  2203] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2204/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.9 ms)
INFO:root:[1,  2204] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2205/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1284.9 ms)
INFO:root:[1,  2205] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2206/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.0 ms)
INFO:root:[1,  2206] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2207/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.1 ms)
INFO:root:[1,  2207] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2208/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.47e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.2 ms)
INFO:root:[1,  2208] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2209/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.2 ms)
INFO:root:[1,  2209] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2210/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.3 ms)
INFO:root:[1,  2210] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2211/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.5 ms)
INFO:root:[1,  2211] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2212/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.5 ms)
INFO:root:[1,  2212] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2213/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.6 ms)
INFO:root:[1,  2213] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2214/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.7 ms)
INFO:root:[1,  2214] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2215/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.7 ms)
INFO:root:[1,  2215] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2216/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.8 ms)
INFO:root:[1,  2216] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2217/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1285.9 ms)
INFO:root:[1,  2217] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2218/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.0 ms)
INFO:root:[1,  2218] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2219/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.1 ms)
INFO:root:[1,  2219] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2220/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.2 ms)
INFO:root:[1,  2220] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2221/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.2 ms)
INFO:root:[1,  2221] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2222/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.3 ms)
INFO:root:[1,  2222] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2223/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.4 ms)
INFO:root:[1,  2223] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2224/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.5 ms)
INFO:root:[1,  2224] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2225/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.6 ms)
INFO:root:[1,  2225] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2226/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.6 ms)
INFO:root:[1,  2226] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2227/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.7 ms)
INFO:root:[1,  2227] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2228/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.8 ms)
INFO:root:[1,  2228] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2229/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1286.9 ms)
INFO:root:[1,  2229] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2230/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.46e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.0 ms)
INFO:root:[1,  2230] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2231/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.1 ms)
INFO:root:[1,  2231] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2232/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.2 ms)
INFO:root:[1,  2232] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2233/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.4 ms)
INFO:root:[1,  2233] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2234/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.4 ms)
INFO:root:[1,  2234] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2235/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.5 ms)
INFO:root:[1,  2235] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2236/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.6 ms)
INFO:root:[1,  2236] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2237/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.7 ms)
INFO:root:[1,  2237] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2238/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.8 ms)
INFO:root:[1,  2238] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2239/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.9 ms)
INFO:root:[1,  2239] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2240/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1287.9 ms)
INFO:root:[1,  2240] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2241/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.0 ms)
INFO:root:[1,  2241] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2242/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.1 ms)
INFO:root:[1,  2242] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2243/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.2 ms)
INFO:root:[1,  2243] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2244/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.3 ms)
INFO:root:[1,  2244] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2245/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.4 ms)
INFO:root:[1,  2245] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2246/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.5 ms)
INFO:root:[1,  2246] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2247/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.6 ms)
INFO:root:[1,  2247] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2248/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.7 ms)
INFO:root:[1,  2248] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2249/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.8 ms)
INFO:root:[1,  2249] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2250/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.8 ms)
INFO:root:[1,  2250] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2251/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.45e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1288.9 ms)
INFO:root:[1,  2251] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2252/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.0 ms)
INFO:root:[1,  2252] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2253/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.1 ms)
INFO:root:[1,  2253] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2254/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.2 ms)
INFO:root:[1,  2254] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2255/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.2 ms)
INFO:root:[1,  2255] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2256/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.3 ms)
INFO:root:[1,  2256] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2257/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.4 ms)
INFO:root:[1,  2257] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2258/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.5 ms)
INFO:root:[1,  2258] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2259/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.6 ms)
INFO:root:[1,  2259] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2260/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.7 ms)
INFO:root:[1,  2260] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2261/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.7 ms)
INFO:root:[1,  2261] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2262/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.8 ms)
INFO:root:[1,  2262] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2263/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1289.9 ms)
INFO:root:[1,  2263] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2264/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.0 ms)
INFO:root:[1,  2264] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2265/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.1 ms)
INFO:root:[1,  2265] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2266/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.2 ms)
INFO:root:[1,  2266] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2267/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.3 ms)
INFO:root:[1,  2267] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2268/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.3 ms)
INFO:root:[1,  2268] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2269/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.4 ms)
INFO:root:[1,  2269] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2270/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.5 ms)
INFO:root:[1,  2270] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2271/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.6 ms)
INFO:root:[1,  2271] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2272/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.44e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.7 ms)
INFO:root:[1,  2272] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2273/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.8 ms)
INFO:root:[1,  2273] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2274/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1290.9 ms)
INFO:root:[1,  2274] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2275/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.0 ms)
INFO:root:[1,  2275] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2276/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.1 ms)
INFO:root:[1,  2276] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2277/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.1 ms)
INFO:root:[1,  2277] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2278/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.2 ms)
INFO:root:[1,  2278] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2279/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.3 ms)
INFO:root:[1,  2279] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2280/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.4 ms)
INFO:root:[1,  2280] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2281/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.5 ms)
INFO:root:[1,  2281] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2282/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.6 ms)
INFO:root:[1,  2282] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2283/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.7 ms)
INFO:root:[1,  2283] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2284/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.8 ms)
INFO:root:[1,  2284] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2285/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1291.9 ms)
INFO:root:[1,  2285] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2286/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.0 ms)
INFO:root:[1,  2286] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2287/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.1 ms)
INFO:root:[1,  2287] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2288/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.1 ms)
INFO:root:[1,  2288] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2289/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.2 ms)
INFO:root:[1,  2289] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2290/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.3 ms)
INFO:root:[1,  2290] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2291/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.4 ms)
INFO:root:[1,  2291] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2292/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.5 ms)
INFO:root:[1,  2292] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2293/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.6 ms)
INFO:root:[1,  2293] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2294/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.43e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.7 ms)
INFO:root:[1,  2294] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2295/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.8 ms)
INFO:root:[1,  2295] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2296/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.8 ms)
INFO:root:[1,  2296] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2297/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1292.9 ms)
INFO:root:[1,  2297] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2298/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.0 ms)
INFO:root:[1,  2298] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2299/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.1 ms)
INFO:root:[1,  2299] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2300/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.2 ms)
INFO:root:[1,  2300] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2301/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.3 ms)
INFO:root:[1,  2301] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2302/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.3 ms)
INFO:root:[1,  2302] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2303/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.4 ms)
INFO:root:[1,  2303] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2304/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.5 ms)
INFO:root:[1,  2304] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2305/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.5 ms)
INFO:root:[1,  2305] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2306/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.6 ms)
INFO:root:[1,  2306] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2307/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.7 ms)
INFO:root:[1,  2307] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2308/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.8 ms)
INFO:root:[1,  2308] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2309/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1293.9 ms)
INFO:root:[1,  2309] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2310/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.0 ms)
INFO:root:[1,  2310] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2311/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.1 ms)
INFO:root:[1,  2311] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2312/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.1 ms)
INFO:root:[1,  2312] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2313/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.3 ms)
INFO:root:[1,  2313] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2314/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.3 ms)
INFO:root:[1,  2314] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2315/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.42e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.4 ms)
INFO:root:[1,  2315] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2316/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.5 ms)
INFO:root:[1,  2316] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2317/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.6 ms)
INFO:root:[1,  2317] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2318/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.7 ms)
INFO:root:[1,  2318] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2319/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.8 ms)
INFO:root:[1,  2319] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2320/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1294.9 ms)
INFO:root:[1,  2320] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2321/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.0 ms)
INFO:root:[1,  2321] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2322/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.1 ms)
INFO:root:[1,  2322] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2323/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.2 ms)
INFO:root:[1,  2323] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2324/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.3 ms)
INFO:root:[1,  2324] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2325/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.3 ms)
INFO:root:[1,  2325] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2326/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.4 ms)
INFO:root:[1,  2326] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2327/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.5 ms)
INFO:root:[1,  2327] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2328/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.6 ms)
INFO:root:[1,  2328] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2329/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.7 ms)
INFO:root:[1,  2329] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2330/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.8 ms)
INFO:root:[1,  2330] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2331/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.8 ms)
INFO:root:[1,  2331] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2332/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1295.9 ms)
INFO:root:[1,  2332] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2333/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.0 ms)
INFO:root:[1,  2333] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2334/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.1 ms)
INFO:root:[1,  2334] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2335/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.1 ms)
INFO:root:[1,  2335] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2336/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.41e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.2 ms)
INFO:root:[1,  2336] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2337/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.3 ms)
INFO:root:[1,  2337] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2338/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.4 ms)
INFO:root:[1,  2338] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2339/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.4 ms)
INFO:root:[1,  2339] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2340/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.5 ms)
INFO:root:[1,  2340] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2341/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.6 ms)
INFO:root:[1,  2341] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2342/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.7 ms)
INFO:root:[1,  2342] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2343/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.8 ms)
INFO:root:[1,  2343] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2344/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1296.9 ms)
INFO:root:[1,  2344] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2345/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.0 ms)
INFO:root:[1,  2345] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2346/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.1 ms)
INFO:root:[1,  2346] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2347/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.2 ms)
INFO:root:[1,  2347] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2348/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.3 ms)
INFO:root:[1,  2348] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2349/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.4 ms)
INFO:root:[1,  2349] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2350/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.4 ms)
INFO:root:[1,  2350] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2351/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.5 ms)
INFO:root:[1,  2351] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2352/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.6 ms)
INFO:root:[1,  2352] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2353/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.7 ms)
INFO:root:[1,  2353] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2354/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.7 ms)
INFO:root:[1,  2354] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2355/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.8 ms)
INFO:root:[1,  2355] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2356/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1297.9 ms)
INFO:root:[1,  2356] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2357/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.0 ms)
INFO:root:[1,  2357] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2358/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.40e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.1 ms)
INFO:root:[1,  2358] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2359/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.2 ms)
INFO:root:[1,  2359] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2360/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.3 ms)
INFO:root:[1,  2360] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2361/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.4 ms)
INFO:root:[1,  2361] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2362/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.5 ms)
INFO:root:[1,  2362] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2363/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.6 ms)
INFO:root:[1,  2363] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2364/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.7 ms)
INFO:root:[1,  2364] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2365/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.8 ms)
INFO:root:[1,  2365] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2366/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.8 ms)
INFO:root:[1,  2366] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2367/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1298.9 ms)
INFO:root:[1,  2367] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2368/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.0 ms)
INFO:root:[1,  2368] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2369/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.1 ms)
INFO:root:[1,  2369] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2370/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.1 ms)
INFO:root:[1,  2370] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2371/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.2 ms)
INFO:root:[1,  2371] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2372/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.3 ms)
INFO:root:[1,  2372] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2373/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.4 ms)
INFO:root:[1,  2373] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2374/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.5 ms)
INFO:root:[1,  2374] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2375/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.5 ms)
INFO:root:[1,  2375] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2376/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.6 ms)
INFO:root:[1,  2376] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2377/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.7 ms)
INFO:root:[1,  2377] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2378/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.8 ms)
INFO:root:[1,  2378] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2379/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.39e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.8 ms)
INFO:root:[1,  2379] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2380/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1299.9 ms)
INFO:root:[1,  2380] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2381/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.0 ms)
INFO:root:[1,  2381] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2382/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.1 ms)
INFO:root:[1,  2382] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2383/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.2 ms)
INFO:root:[1,  2383] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2384/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.2 ms)
INFO:root:[1,  2384] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2385/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.3 ms)
INFO:root:[1,  2385] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2386/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.4 ms)
INFO:root:[1,  2386] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2387/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.5 ms)
INFO:root:[1,  2387] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2388/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.6 ms)
INFO:root:[1,  2388] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2389/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.6 ms)
INFO:root:[1,  2389] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2390/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.7 ms)
INFO:root:[1,  2390] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2391/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.8 ms)
INFO:root:[1,  2391] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2392/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1300.9 ms)
INFO:root:[1,  2392] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2393/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.0 ms)
INFO:root:[1,  2393] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2394/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.1 ms)
INFO:root:[1,  2394] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2395/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.1 ms)
INFO:root:[1,  2395] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2396/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.2 ms)
INFO:root:[1,  2396] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2397/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.3 ms)
INFO:root:[1,  2397] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2398/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.4 ms)
INFO:root:[1,  2398] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2399/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.5 ms)
INFO:root:[1,  2399] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2400/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.38e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.6 ms)
INFO:root:[1,  2400] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2401/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.7 ms)
INFO:root:[1,  2401] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2402/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.8 ms)
INFO:root:[1,  2402] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2403/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1301.9 ms)
INFO:root:[1,  2403] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2404/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.0 ms)
INFO:root:[1,  2404] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2405/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.1 ms)
INFO:root:[1,  2405] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2406/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.2 ms)
INFO:root:[1,  2406] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2407/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.3 ms)
INFO:root:[1,  2407] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2408/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.4 ms)
INFO:root:[1,  2408] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2409/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.4 ms)
INFO:root:[1,  2409] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2410/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.5 ms)
INFO:root:[1,  2410] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2411/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.6 ms)
INFO:root:[1,  2411] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2412/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.7 ms)
INFO:root:[1,  2412] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2413/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.8 ms)
INFO:root:[1,  2413] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2414/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1302.9 ms)
INFO:root:[1,  2414] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2415/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.0 ms)
INFO:root:[1,  2415] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2416/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.1 ms)
INFO:root:[1,  2416] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2417/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.2 ms)
INFO:root:[1,  2417] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2418/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.2 ms)
INFO:root:[1,  2418] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2419/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.3 ms)
INFO:root:[1,  2419] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2420/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.4 ms)
INFO:root:[1,  2420] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2421/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.5 ms)
INFO:root:[1,  2421] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2422/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.37e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.6 ms)
INFO:root:[1,  2422] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2423/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.7 ms)
INFO:root:[1,  2423] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2424/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.7 ms)
INFO:root:[1,  2424] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2425/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.8 ms)
INFO:root:[1,  2425] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2426/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1303.9 ms)
INFO:root:[1,  2426] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2427/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.0 ms)
INFO:root:[1,  2427] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2428/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.1 ms)
INFO:root:[1,  2428] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2429/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.2 ms)
INFO:root:[1,  2429] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2430/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.3 ms)
INFO:root:[1,  2430] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2431/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.4 ms)
INFO:root:[1,  2431] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2432/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.4 ms)
INFO:root:[1,  2432] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2433/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.5 ms)
INFO:root:[1,  2433] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2434/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.6 ms)
INFO:root:[1,  2434] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2435/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.7 ms)
INFO:root:[1,  2435] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2436/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.8 ms)
INFO:root:[1,  2436] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2437/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1304.9 ms)
INFO:root:[1,  2437] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2438/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.0 ms)
INFO:root:[1,  2438] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2439/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.1 ms)
INFO:root:[1,  2439] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2440/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.2 ms)
INFO:root:[1,  2440] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2441/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.3 ms)
INFO:root:[1,  2441] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2442/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.4 ms)
INFO:root:[1,  2442] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2443/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.36e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.4 ms)
INFO:root:[1,  2443] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2444/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.5 ms)
INFO:root:[1,  2444] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2445/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.6 ms)
INFO:root:[1,  2445] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2446/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.7 ms)
INFO:root:[1,  2446] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2447/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.8 ms)
INFO:root:[1,  2447] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2448/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1305.9 ms)
INFO:root:[1,  2448] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2449/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.0 ms)
INFO:root:[1,  2449] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2450/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.1 ms)
INFO:root:[1,  2450] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2451/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.1 ms)
INFO:root:[1,  2451] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2452/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.2 ms)
INFO:root:[1,  2452] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2453/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.3 ms)
INFO:root:[1,  2453] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2454/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.4 ms)
INFO:root:[1,  2454] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2455/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.5 ms)
INFO:root:[1,  2455] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2456/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.6 ms)
INFO:root:[1,  2456] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2457/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.7 ms)
INFO:root:[1,  2457] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2458/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.8 ms)
INFO:root:[1,  2458] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2459/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1306.9 ms)
INFO:root:[1,  2459] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2460/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.0 ms)
INFO:root:[1,  2460] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2461/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.0 ms)
INFO:root:[1,  2461] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2462/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.1 ms)
INFO:root:[1,  2462] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2463/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.2 ms)
INFO:root:[1,  2463] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2464/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.35e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.4 ms)
INFO:root:[1,  2464] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2465/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.4 ms)
INFO:root:[1,  2465] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2466/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.5 ms)
INFO:root:[1,  2466] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2467/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.7 ms)
INFO:root:[1,  2467] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2468/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.7 ms)
INFO:root:[1,  2468] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2469/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.8 ms)
INFO:root:[1,  2469] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2470/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1307.9 ms)
INFO:root:[1,  2470] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2471/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.0 ms)
INFO:root:[1,  2471] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2472/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.1 ms)
INFO:root:[1,  2472] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2473/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.2 ms)
INFO:root:[1,  2473] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2474/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.3 ms)
INFO:root:[1,  2474] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2475/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.4 ms)
INFO:root:[1,  2475] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2476/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.5 ms)
INFO:root:[1,  2476] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2477/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.6 ms)
INFO:root:[1,  2477] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2478/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.7 ms)
INFO:root:[1,  2478] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2479/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.8 ms)
INFO:root:[1,  2479] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2480/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.8 ms)
INFO:root:[1,  2480] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2481/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1308.9 ms)
INFO:root:[1,  2481] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2482/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.0 ms)
INFO:root:[1,  2482] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2483/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.1 ms)
INFO:root:[1,  2483] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2484/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.2 ms)
INFO:root:[1,  2484] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2485/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.2 ms)
INFO:root:[1,  2485] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2486/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.34e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.3 ms)
INFO:root:[1,  2486] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2487/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.4 ms)
INFO:root:[1,  2487] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2488/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.5 ms)
INFO:root:[1,  2488] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2489/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.5 ms)
INFO:root:[1,  2489] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2490/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.6 ms)
INFO:root:[1,  2490] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2491/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.7 ms)
INFO:root:[1,  2491] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2492/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.7 ms)
INFO:root:[1,  2492] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2493/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.8 ms)
INFO:root:[1,  2493] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2494/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1309.9 ms)
INFO:root:[1,  2494] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2495/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.0 ms)
INFO:root:[1,  2495] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2496/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.1 ms)
INFO:root:[1,  2496] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2497/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.2 ms)
INFO:root:[1,  2497] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2498/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.2 ms)
INFO:root:[1,  2498] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2499/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.3 ms)
INFO:root:[1,  2499] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2500/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.4 ms)
INFO:root:[1,  2500] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2501/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.5 ms)
INFO:root:[1,  2501] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2502/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.6 ms)
INFO:root:[1,  2502] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2503/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.6 ms)
INFO:root:[1,  2503] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2504/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.7 ms)
INFO:root:[1,  2504] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2505/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.8 ms)
INFO:root:[1,  2505] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2506/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1310.9 ms)
INFO:root:[1,  2506] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2507/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.33e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.0 ms)
INFO:root:[1,  2507] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2508/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.1 ms)
INFO:root:[1,  2508] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2509/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.2 ms)
INFO:root:[1,  2509] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2510/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.3 ms)
INFO:root:[1,  2510] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2511/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.4 ms)
INFO:root:[1,  2511] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2512/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.5 ms)
INFO:root:[1,  2512] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2513/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.6 ms)
INFO:root:[1,  2513] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2514/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.7 ms)
INFO:root:[1,  2514] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2515/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.8 ms)
INFO:root:[1,  2515] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2516/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1311.9 ms)
INFO:root:[1,  2516] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2517/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.0 ms)
INFO:root:[1,  2517] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2518/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.2 ms)
INFO:root:[1,  2518] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2519/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.3 ms)
INFO:root:[1,  2519] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2520/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.3 ms)
INFO:root:[1,  2520] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2521/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.4 ms)
INFO:root:[1,  2521] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2522/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.5 ms)
INFO:root:[1,  2522] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2523/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.6 ms)
INFO:root:[1,  2523] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2524/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.7 ms)
INFO:root:[1,  2524] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2525/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.7 ms)
INFO:root:[1,  2525] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2526/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.8 ms)
INFO:root:[1,  2526] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2527/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1312.9 ms)
INFO:root:[1,  2527] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2528/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.32e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.0 ms)
INFO:root:[1,  2528] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2529/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.1 ms)
INFO:root:[1,  2529] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2530/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.2 ms)
INFO:root:[1,  2530] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2531/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.01e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.3 ms)
INFO:root:[1,  2531] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2532/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.4 ms)
INFO:root:[1,  2532] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2533/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.5 ms)
INFO:root:[1,  2533] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2534/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.6 ms)
INFO:root:[1,  2534] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2535/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.6 ms)
INFO:root:[1,  2535] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2536/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.7 ms)
INFO:root:[1,  2536] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2537/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.8 ms)
INFO:root:[1,  2537] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2538/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1313.9 ms)
INFO:root:[1,  2538] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2539/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.0 ms)
INFO:root:[1,  2539] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2540/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.0 ms)
INFO:root:[1,  2540] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2541/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.1 ms)
INFO:root:[1,  2541] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2542/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.2 ms)
INFO:root:[1,  2542] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2543/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.3 ms)
INFO:root:[1,  2543] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2544/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.4 ms)
INFO:root:[1,  2544] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2545/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.5 ms)
INFO:root:[1,  2545] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2546/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.6 ms)
INFO:root:[1,  2546] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2547/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.7 ms)
INFO:root:[1,  2547] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2548/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.7 ms)
INFO:root:[1,  2548] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2549/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.8 ms)
INFO:root:[1,  2549] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2550/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.31e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1314.9 ms)
INFO:root:[1,  2550] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2551/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.0 ms)
INFO:root:[1,  2551] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2552/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.1 ms)
INFO:root:[1,  2552] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2553/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.2 ms)
INFO:root:[1,  2553] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2554/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.3 ms)
INFO:root:[1,  2554] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2555/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.4 ms)
INFO:root:[1,  2555] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2556/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.5 ms)
INFO:root:[1,  2556] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2557/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.5 ms)
INFO:root:[1,  2557] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2558/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.7 ms)
INFO:root:[1,  2558] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2559/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.7 ms)
INFO:root:[1,  2559] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2560/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.8 ms)
INFO:root:[1,  2560] grad_stats: [nan nan] (nan, nan)
parent logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
subclass logits: tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       dtype=torch.bfloat16, grad_fn=<_DDPSinkBackward>)
INFO:root:[1,  2561/ 2562] - train_losses - Parent Class: nan - Children class: nan -Autoencoder Loss (total): nan - Reconstruction/K-Means Loss: [nan / nan] - Consistency Loss: [0.0000] - VICReg Loss: [0.0000][wd: 5.02e-02] [lr: 7.30e-05] [autoencoder lr: 1.57e-04][mem: 6.87e+04] (1315.6 ms)
INFO:root:[1,  2561] grad_stats: [nan nan] (nan, nan)
INFO:root:Autoencoder Training...
INFO:root: - - Epoch: 37 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[37,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.00e-04][mem: 6.87e+04](372.8 ms)
INFO:root:[37,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.01e-04][mem: 6.87e+04](323.0 ms)
INFO:root:[37,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.02e-04][mem: 6.87e+04](322.8 ms)
INFO:root:[37,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.02e-04][mem: 6.87e+04](322.8 ms)
INFO:root:[37,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.03e-04][mem: 6.87e+04](322.7 ms)
INFO:root:[37,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.04e-04][mem: 6.87e+04](322.7 ms)
INFO:root:[37,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.05e-04][mem: 6.87e+04](322.7 ms)
INFO:root:[37,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.05e-04][mem: 6.87e+04](322.7 ms)
INFO:root:[37,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.06e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.07e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.08e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.09e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.09e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.10e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.11e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.12e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.12e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.13e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.14e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.15e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.16e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.16e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.17e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.18e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.19e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[37,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.20e-04][mem: 6.87e+04](322.6 ms)
INFO:root: - - Epoch: 38 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[38,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.20e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.21e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.22e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.22e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.23e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.24e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.25e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.25e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.26e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.27e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.28e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.29e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.29e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.30e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.31e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.32e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.32e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.33e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.34e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.35e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.36e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.36e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.37e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.38e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.39e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[38,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.40e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 39 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[39,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.40e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.41e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.42e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.42e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.43e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.44e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.45e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.45e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.46e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.47e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.48e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.49e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.49e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.50e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.51e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.52e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.52e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.53e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.54e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.55e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.56e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.56e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.57e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.58e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.59e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[39,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.60e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 40 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[40,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.60e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.61e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.62e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.62e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.63e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.64e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.65e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.65e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.66e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.67e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.68e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.69e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.69e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.70e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.71e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.72e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.72e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.73e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.74e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.75e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.76e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.76e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.77e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.78e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.79e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[40,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.80e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 41 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[41,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.80e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.81e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.82e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.82e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.83e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.84e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.85e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.85e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.86e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.87e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.88e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.89e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.89e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.90e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.91e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.92e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.92e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.93e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.94e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.95e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.96e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.96e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.97e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.98e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[41,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 42 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[42,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[42,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 43 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[43,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[43,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 44 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[44,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 2.00e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[44,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 45 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[45,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[45,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root: - - Epoch: 46 - - 
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[46,     0/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.5 ms)
INFO:root:[46,   100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[46,   200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[46,   300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.6 ms)
INFO:root:[46,   400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.7 ms)
INFO:root:[46,   500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.7 ms)
INFO:root:[46,   600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.8 ms)
INFO:root:[46,   700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.8 ms)
INFO:root:[46,   800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.9 ms)
INFO:root:[46,   900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](322.9 ms)
INFO:root:[46,  1000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.0 ms)
INFO:root:[46,  1100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.0 ms)
INFO:root:[46,  1200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.0 ms)
INFO:root:[46,  1300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.1 ms)
INFO:root:[46,  1400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.1 ms)
INFO:root:[46,  1500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.2 ms)
INFO:root:[46,  1600/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.2 ms)
INFO:root:[46,  1700/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.2 ms)
INFO:root:[46,  1800/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.3 ms)
INFO:root:[46,  1900/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.3 ms)
INFO:root:[46,  2000/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.4 ms)
INFO:root:[46,  2100/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.4 ms)
INFO:root:[46,  2200/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.99e-04][mem: 6.87e+04](323.5 ms)
INFO:root:[46,  2300/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.98e-04][mem: 6.87e+04](323.5 ms)
INFO:root:[46,  2400/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.98e-04][mem: 6.87e+04](323.5 ms)
INFO:root:[46,  2500/ 2562] - [Autoencoder Training] [Autoencoder Loss: nan] [autoencoder lr: 1.98e-04][mem: 6.87e+04](323.6 ms)
INFO:root:Asserting cache length
INFO:root:Reinitializing centroids
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [6,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [6,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [6,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [32,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [33,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [34,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [35,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [36,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [37,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [38,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [39,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [40,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [41,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [42,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [43,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [44,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [45,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [46,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [47,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [48,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [49,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [50,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [51,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [52,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [53,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [54,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [55,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [56,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [57,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [58,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [59,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [60,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [61,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [62,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [63,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [67,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [68,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [69,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [70,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [71,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [72,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [73,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [74,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [75,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [76,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [77,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [78,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [79,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [80,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [81,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [82,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [83,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [84,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [85,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [86,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [87,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [88,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [89,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [90,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [91,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [92,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [93,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [94,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [95,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [96,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [97,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [98,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [99,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [100,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [101,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [102,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [103,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [104,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [105,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [106,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [107,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [108,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [109,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [110,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [111,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [112,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [113,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [114,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [115,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [116,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [117,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [118,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [119,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [120,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [121,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [122,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [123,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [124,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [125,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [126,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [127,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [0,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [1,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [2,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [3,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [4,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [5,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [6,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [7,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [8,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [9,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [10,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [11,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [12,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [13,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [14,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [15,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [16,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [17,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [18,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [19,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [20,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [21,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [22,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [23,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [24,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [25,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [26,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [27,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [28,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [29,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [30,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [1,0,0], thread: [31,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [32,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [33,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [34,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [35,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [36,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [37,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [38,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [39,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [40,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [41,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [42,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [43,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [44,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [45,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [46,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [47,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [48,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [49,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [50,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [51,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [52,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [53,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [54,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [55,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [56,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [57,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [58,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [59,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [60,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [61,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [62,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [63,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [67,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [68,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [69,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [70,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [71,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [72,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [73,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [74,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [75,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [76,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [77,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [78,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [79,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [80,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [81,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [82,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [83,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [84,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [85,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [86,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [87,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [88,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [89,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [90,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [91,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [92,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [93,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [94,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [95,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [96,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [97,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [98,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [99,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [100,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [101,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [102,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [103,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [104,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [105,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [106,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [107,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [108,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [109,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [110,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [111,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [112,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [113,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [114,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [115,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [116,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [117,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [118,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [119,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [120,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [121,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [122,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [123,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [124,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [125,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [126,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [127,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [0,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [1,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [2,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [3,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [4,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [5,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [6,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [7,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [8,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [9,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [10,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [11,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [12,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [13,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [14,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [15,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [16,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [17,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [18,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [19,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [20,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [21,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [22,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [23,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [24,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [25,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [26,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [27,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [28,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [29,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [30,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [2,0,0], thread: [31,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [32,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [33,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [34,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [35,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [36,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [37,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [38,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [39,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [40,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [41,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [42,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [43,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [44,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [45,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [46,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [47,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [48,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [49,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [50,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [51,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [52,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [53,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [54,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [55,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [56,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [57,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [58,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [59,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [60,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [61,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [62,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [63,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [0,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [1,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [2,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [3,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [4,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [5,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [6,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [7,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [8,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [9,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [10,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [11,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [12,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [13,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [14,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [15,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [16,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [17,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [18,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [19,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [20,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [21,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [22,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [23,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [24,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [25,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [26,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [27,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [28,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [29,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [30,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [31,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [96,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [97,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [98,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [99,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [100,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [101,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [102,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [103,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [104,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [105,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [106,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [107,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [108,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [109,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [110,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [111,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [112,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [113,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [114,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [115,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [116,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [117,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [118,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [119,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [120,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [121,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [122,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [123,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [124,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [125,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [126,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [127,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [67,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [68,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [69,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [70,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [71,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [72,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [73,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [74,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [75,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [76,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [77,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [78,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [79,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [80,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [81,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [82,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [83,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [84,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [85,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [86,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [87,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [88,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [89,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [90,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [91,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [92,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [93,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [94,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [4,0,0], thread: [95,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [32,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [33,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [34,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [35,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [36,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [37,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [38,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [39,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [40,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [41,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [42,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [43,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [44,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [45,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [46,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [47,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [48,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [49,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [50,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [51,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [52,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [53,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [54,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [55,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [56,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [57,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [58,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [59,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [60,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [61,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [62,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [63,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [67,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [68,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [69,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [70,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [71,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [72,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [73,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [74,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [75,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [76,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [77,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [78,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [79,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [80,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [81,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [82,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [83,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [84,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [85,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [86,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [87,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [88,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [89,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [90,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [91,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [92,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [93,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [94,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [95,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [96,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [97,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [98,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [99,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [100,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [101,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [102,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [103,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [104,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [105,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [106,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [107,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [108,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [109,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [110,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [111,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [112,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [113,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [114,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [115,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [116,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [117,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [118,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [119,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [120,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [121,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [122,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [123,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [124,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [125,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [126,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [127,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [0,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [1,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [2,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [3,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [4,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [5,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [6,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [7,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [8,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [9,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [10,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [11,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [12,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [13,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [14,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [15,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [16,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [17,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [18,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [19,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [20,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [21,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [22,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [23,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [24,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [25,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [26,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [27,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [28,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [29,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [30,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [0,0,0], thread: [31,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [0,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [1,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [2,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [3,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [4,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [5,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [6,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [7,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [8,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [9,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [10,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [11,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [12,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [13,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [14,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [15,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [16,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [17,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [18,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [19,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [20,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [21,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [22,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [23,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [24,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [25,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [26,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [27,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [28,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [29,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [30,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [31,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [32,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [33,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [34,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [35,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [36,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [37,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [38,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [39,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [40,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [41,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [42,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [43,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [44,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [45,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [46,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [47,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [48,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [49,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [50,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [51,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [52,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [53,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [54,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [55,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [56,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [57,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [58,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [59,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [60,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [61,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [62,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [63,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [67,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [68,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [69,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [70,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [71,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [72,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [73,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [74,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [75,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [76,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [77,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [78,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [79,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [80,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [81,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [82,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [83,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [84,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [85,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [86,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [87,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [88,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [89,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [90,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [91,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [92,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [93,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [94,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [95,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [96,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [97,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [98,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [99,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [100,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [101,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [102,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [103,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [104,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [105,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [106,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [107,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [108,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [109,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [110,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [111,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [112,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [113,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [114,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [115,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [116,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [117,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [118,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [119,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [120,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [121,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [122,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [123,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [124,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [125,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [126,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [5,0,0], thread: [127,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [32,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [33,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [34,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [35,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [36,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [37,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [38,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [39,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [40,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [41,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [42,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [43,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [44,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [45,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [46,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [47,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [48,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [49,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [50,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [51,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [52,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [53,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [54,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [55,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [56,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [57,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [58,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [59,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [60,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [61,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [62,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [63,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [64,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [65,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [66,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [67,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [68,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [69,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [70,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [71,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [72,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [73,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [74,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [75,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [76,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [77,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [78,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [79,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [80,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [81,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [82,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [83,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [84,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [85,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [86,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [87,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [88,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [89,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [90,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [91,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [92,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [93,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [94,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [95,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [96,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [97,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [98,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [99,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [100,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [101,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [102,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [103,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [104,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [105,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [106,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [107,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [108,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [109,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [110,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [111,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [112,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [113,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [114,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [115,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [116,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [117,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [118,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [119,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [120,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [121,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [122,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [123,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [124,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [125,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [126,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [127,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [0,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [1,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [2,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [3,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [4,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [5,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [6,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [7,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [8,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [9,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [10,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [11,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [12,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [13,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [14,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [15,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [16,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [17,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [18,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [19,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [20,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [21,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [22,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [23,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [24,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [25,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [26,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [27,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [28,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [29,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [30,0,0] Assertion `dstIndex < dstAddDimSize` failed.
/opt/conda/conda-bld/pytorch_1716905969118/work/aten/src/ATen/native/cuda/Indexing.cu:805: indexFuncLargeIndex: block: [3,0,0], thread: [31,0,0] Assertion `dstIndex < dstAddDimSize` failed.
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_FGDCC.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_FGDCC.py", line 824, in main
    M_losses = k_means_module.update(cached_features, device, empty_clusters_per_epoch)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 208, in update
    _, batch_k_means_loss = self.iterative_kmeans(xb, key, device, empty_clusters_per_epoch)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 252, in iterative_kmeans
    new_centroids[non_empty_mask] /= counts[non_empty_mask].unsqueeze(1).float()
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[rank0]:[W CUDAGuardImpl.h:118] Warning: CUDA warning: device-side assert triggered (function destroyEvent)
terminate called after throwing an instance of 'c10::Error'
  what():  CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at /opt/conda/conda-bld/pytorch_1716905969118/work/c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f38f568a897 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f38f563ab25 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x7f38f57646f8 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1d8b6 (0x7f38f572f8b6 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1f5c3 (0x7f38f57315c3 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x1f902 (0x7f38f5731902 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5a5810 (0x7f395619d810 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6a36f (0x7f38f566f36f in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x7f38f56681cb in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x7f38f5668379 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #10: c10d::Reducer::~Reducer() + 0x5c4 (0x7f394ea190d4 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #11: std::_Sp_counted_ptr<c10d::Reducer*, (__gnu_cxx::_Lock_policy)2>::_M_dispose() + 0x12 (0x7f39568e7102 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #12: std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() + 0x48 (0x7f3956067a08 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #13: <unknown function> + 0xcf2ca1 (0x7f39568eaca1 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #14: <unknown function> + 0x47a902 (0x7f3956072902 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #15: <unknown function> + 0x47b901 (0x7f3956073901 in /home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #16: <unknown function> + 0x20812b (0x55b5d9c9b12b in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #17: <unknown function> + 0x25a914 (0x55b5d9ced914 in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #18: <unknown function> + 0x25927f (0x55b5d9cec27f in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #19: <unknown function> + 0x23a427 (0x55b5d9ccd427 in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #20: <unknown function> + 0x2391a4 (0x55b5d9ccc1a4 in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #21: <unknown function> + 0x23919d (0x55b5d9ccc19d in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #22: <unknown function> + 0x23919d (0x55b5d9ccc19d in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #23: <unknown function> + 0x23919d (0x55b5d9ccc19d in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #24: <unknown function> + 0x24c07e (0x55b5d9cdf07e in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #25: <unknown function> + 0x11b0ab (0x55b5d9bae0ab in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #26: PyEval_EvalCode + 0xae (0x55b5d9d5840e in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #27: <unknown function> + 0x2e911a (0x55b5d9d7c11a in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #28: <unknown function> + 0x2e430b (0x55b5d9d7730b in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #29: PyRun_StringFlags + 0x62 (0x55b5d9d691b2 in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #30: PyRun_SimpleStringFlags + 0x3c (0x55b5d9d690cc in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #31: Py_RunMain + 0x450 (0x55b5d9d87b80 in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #32: Py_BytesMain + 0x37 (0x55b5d9d40997 in /home/rtcalumby/miniconda3/envs/py382/bin/python)
frame #33: __libc_start_main + 0xf3 (0x7f395f63d083 in /lib/x86_64-linux-gnu/libc.so.6)
frame #34: <unknown function> + 0x2ad811 (0x55b5d9d40811 in /home/rtcalumby/miniconda3/envs/py382/bin/python)

