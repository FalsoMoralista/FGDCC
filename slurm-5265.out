INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/plantnet300k.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'cache_path': '/home/rtcalumby/adam/luciano/DeepCluster/cache/plantnet_300k',
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'dinov2': False,
    'dinov2_meta': {'model_name': 'vit_large'},
    'k_means': {'K_range': [2, 3, 4, 5], 'reinitialize_centroids': 5},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k_exp68',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-05,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.0001,
                        'start_lr': 1e-05,
                        'warmup': 25,
                        'weight_decay': 0.05},
    'vicreg': {'alpha': 7.5, 'beta': 25.0, 'gamma': 1.0}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
INFO:root:PairedDataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:ClassificationHead(
  (dropout): Dropout(p=0.15, inplace=False)
  (classifier): Linear(in_features=1280, out_features=15134, bias=True)
)
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
    )
    (blocks): ModuleList(
      (0-31): 32 x Block(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
  )
)
INFO:root:Setting up cache...
INFO:root:Loading cached features at /home/rtcalumby/adam/luciano/DeepCluster/cache/plantnet_300k/ijepa_vit_huge
INFO:root:Done...
INFO:root:Initializing centroids...
Feature Bank classes
dict_keys([573, 944, 919, 285, 173, 378, 223, 892, 3, 644, 999, 32, 240, 60, 11, 382, 761, 423, 598, 499, 527, 953, 153, 471, 123, 402, 1061, 651, 537, 4, 477, 83, 486, 1003, 271, 520, 205, 556, 694, 614, 331, 422, 744, 112, 226, 230, 204, 434, 172, 829, 122, 40, 1048, 201, 313, 428, 108, 84, 413, 26, 319, 203, 354, 97, 175, 135, 2, 140, 483, 811, 405, 787, 827, 495, 63, 875, 412, 152, 448, 535, 238, 104, 88, 342, 65, 810, 741, 19, 218, 31, 263, 360, 536, 685, 45, 162, 643, 669, 376, 470, 532, 691, 23, 141, 727, 68, 410, 114, 322, 465, 388, 443, 615, 1011, 469, 187, 481, 490, 202, 98, 233, 99, 209, 14, 686, 475, 930, 624, 247, 540, 861, 626, 35, 989, 505, 439, 981, 348, 904, 488, 543, 208, 9, 235, 367, 248, 706, 182, 303, 154, 836, 228, 906, 519, 869, 593, 559, 806, 272, 702, 833, 427, 417, 17, 629, 242, 914, 229, 351, 213, 529, 557, 567, 54, 461, 561, 899, 371, 714, 196, 47, 988, 143, 191, 498, 512, 125, 576, 858, 970, 308, 148, 719, 166, 881, 231, 757, 171, 396, 46, 234, 995, 482, 349, 336, 564, 429, 28, 25, 1012, 1059, 245, 982, 783, 174, 241, 298, 243, 845, 458, 244, 27, 932, 550, 181, 455, 95, 986, 212, 146, 126, 334, 39, 521, 73, 144, 355, 420, 239, 383, 513, 579, 437, 856, 92, 363, 510, 66, 571, 36, 56, 431, 188, 38, 432, 1009, 184, 387, 392, 343, 847, 102, 570, 199, 76, 546, 451, 460, 267, 6, 361, 307, 503, 111, 41, 572, 91, 198, 590, 472, 414, 832, 8, 30, 139, 803, 1010, 136, 812, 620, 959, 531, 0, 328, 580, 44, 705, 739, 138, 216, 381, 819, 514, 569, 681, 980, 852, 259, 176, 935, 16, 447, 755, 446, 533, 352, 77, 78, 374, 487, 158, 659, 602, 118, 696, 926, 168, 478, 186, 167, 753, 807, 170, 742, 863, 53, 697, 159, 337, 193, 368, 87, 862, 103, 515, 29, 655, 71, 94, 549, 42, 113, 672, 766, 72, 306, 698, 502, 372, 400, 701, 578, 530, 645, 977, 137, 526, 584, 568, 774, 634, 837, 344, 902, 197, 338, 933, 1045, 1035, 998, 100, 264, 403, 473, 430, 369, 575, 379, 1056, 835, 818, 55, 165, 124, 695, 278, 751, 674, 699, 828, 133, 1, 728, 397, 842, 754, 552, 539, 665, 74, 33, 51, 61, 333, 375, 277, 22, 508, 359, 1000, 596, 80, 1052, 964, 692, 150, 551, 13, 775, 776, 255, 424, 1002, 646, 435, 279, 484, 377, 782, 130, 866, 826, 177, 910, 232, 597, 544, 967, 773, 246, 900, 494, 1063, 501, 466, 1057, 707, 511, 452, 853, 689, 1062, 492, 450, 301, 299, 884, 749, 121, 449, 653, 800, 606, 860, 365, 404, 347, 649, 294, 433, 426, 12, 917, 407, 1060, 784, 657, 991, 789, 909, 34, 18, 637, 419, 673, 192, 131, 1001, 200, 444, 733, 1008, 736, 577, 896, 969, 830, 370, 770, 752, 436, 1027, 979, 356, 523, 399, 335, 890, 406, 898, 903, 668, 990, 297, 762, 621, 560, 734, 416, 844, 566, 821, 195, 1051, 185, 20, 467, 236, 820, 462, 1072, 507, 950, 275, 164, 211, 625, 877, 109, 798, 968, 717, 687, 867, 295, 253, 453, 640, 700, 1020, 920, 346, 380, 1022, 43, 50, 421, 438, 940, 1032, 947, 222, 632, 554, 778, 219, 1021, 300, 973, 922, 628, 408, 1017, 788, 15, 599, 1034, 966, 601, 1047, 961, 353, 855, 395, 221, 616, 796, 261, 609, 517, 1046, 763, 737, 384, 587, 764, 905, 726, 581, 677, 59, 214, 760, 882, 617, 509, 656, 504, 132, 476, 415, 491, 69, 227, 731, 586, 1053, 129, 289, 385, 893, 799, 273, 565, 652, 805, 946, 859, 1036, 340, 311, 841, 327, 189, 64, 207, 563, 391, 704, 323, 848, 268, 639, 315, 251, 266, 210, 889, 928, 445, 955, 916, 671, 127, 633, 528, 678, 257, 951, 1042, 987, 885, 939, 485, 825, 688, 608, 918, 339, 771, 732, 1049, 48, 786, 1078, 588, 746, 937, 781, 838, 149, 972, 929, 895, 831, 1068, 373, 101, 489, 180, 151, 156, 1019, 816, 178, 654, 815, 851, 630, 777, 670, 116, 160, 974, 993, 553, 1055, 147, 913, 357, 823, 134, 1007, 454, 364, 1064, 817, 161, 320, 206, 1031, 538, 85, 611, 600, 921, 954, 1079, 128, 679, 81, 874, 994, 758, 10, 1018, 822, 1014, 693, 119, 330, 106, 585, 711, 843, 619, 418, 296, 872, 658, 675, 70, 518, 627, 442, 463, 480, 834, 220, 809, 341, 574, 1016, 911, 912, 1070, 880, 555, 155, 938, 362, 1043, 545, 785, 496, 105, 660, 534, 548, 747, 318, 879, 638, 1065, 708, 793, 795, 724, 1006, 49, 1050, 283, 997, 329, 282, 871, 260, 661, 541, 67, 712, 393, 850, 37, 456, 237, 648, 21, 716, 169, 288, 1029, 190, 194, 110, 1075, 163, 115, 1033, 93, 963, 713, 120, 965, 398, 849, 721, 441, 978, 281, 876, 1025, 684, 62, 996, 603, 24, 948, 1030, 1077, 58, 86, 1080, 745, 664, 1005, 864, 958, 976, 1069, 942, 925, 52, 90, 642, 366, 613, 5, 594, 516, 284, 589, 57, 474, 117, 971, 934, 280, 1026, 582, 715, 583, 622, 901, 690, 952, 865, 769, 225, 962, 276, 96, 350, 883, 743, 89, 506, 943, 250, 878, 790, 82, 857, 217, 740, 768, 725, 562, 941, 394, 750, 647, 897, 756, 317, 497, 779, 459, 814, 840, 662, 945, 345, 258, 457, 924, 650, 269, 401, 975, 224, 992, 592, 390, 302, 636, 524, 759, 321, 780, 1040, 500, 735, 888, 179, 324, 666, 718, 215, 389, 813, 252, 493, 748, 801, 386, 290, 7, 607, 325, 1041, 326, 312, 270, 314, 854, 254, 936, 107, 956, 1067, 908, 907, 772, 618, 286, 142, 663, 157, 479, 680, 723, 547, 464, 265, 802, 894, 304, 709, 1015, 292, 558, 1076, 332, 291, 591, 729, 468, 923, 682, 316, 1044, 262, 1071, 984, 612, 1074, 839, 722, 957, 409, 525, 1023, 720, 792, 631, 767, 983, 1039, 960, 794, 738, 605, 873, 703, 804, 595, 358, 293, 1058, 641, 667, 256, 1066, 683, 75, 886, 522, 891, 710, 1037, 635, 808, 791, 440, 305, 623, 1024, 274, 287, 309, 1038, 425, 610, 931, 79, 1073, 1054, 870, 824, 604, 868, 887, 183, 542, 730, 310, 411, 1028, 915, 1013, 676, 846, 949, 927, 145, 1004, 797, 985, 249, 765])
